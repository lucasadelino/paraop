{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "faef9f1cb024473194827ce7daeacc3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16d4e115a0194911b895f3e04951cdd8",
              "IPY_MODEL_746e40882e54461aa3fff2ce7ac065ff",
              "IPY_MODEL_f91e5fca2cf3451caecaf6b68763f0f4"
            ],
            "layout": "IPY_MODEL_fb6352207a854f398db79d66c79bc1eb"
          }
        },
        "16d4e115a0194911b895f3e04951cdd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14fe591ab71f4d7dba5424ea416c73f9",
            "placeholder": "​",
            "style": "IPY_MODEL_74468f91f21c4df0a5fa6da4ff681282",
            "value": "model.safetensors: 100%"
          }
        },
        "746e40882e54461aa3fff2ce7ac065ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_348aa42f0a3948f18e9f41e2f3001b2a",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d4d6ce36a1442c294630ed750363d6e",
            "value": 440449768
          }
        },
        "f91e5fca2cf3451caecaf6b68763f0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d364b6cd0174b73b21bccc494552fa8",
            "placeholder": "​",
            "style": "IPY_MODEL_465ad1d9f43d4bc9870480b5170ceca3",
            "value": " 440M/440M [00:01&lt;00:00, 358MB/s]"
          }
        },
        "fb6352207a854f398db79d66c79bc1eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14fe591ab71f4d7dba5424ea416c73f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "74468f91f21c4df0a5fa6da4ff681282": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "348aa42f0a3948f18e9f41e2f3001b2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d4d6ce36a1442c294630ed750363d6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d364b6cd0174b73b21bccc494552fa8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "465ad1d9f43d4bc9870480b5170ceca3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Reading Files"
      ],
      "metadata": {
        "id": "pg5aBCdzNam2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYBoDkEXjRUz",
        "outputId": "d94bb233-631d-47d4-db56-da5dd8ac8862"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.32.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.1+cu121)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn, xxhash, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, fsspec, dill, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, alembic, optuna, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 pyarrow-17.0.0 requests-2.32.3 scikit-multilearn-0.2.0 xxhash-3.4.1\n",
            "Cloning into 'thesis'...\n",
            "remote: Enumerating objects: 114, done.\u001b[K\n",
            "remote: Counting objects: 100% (114/114), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 114 (delta 42), reused 100 (delta 28), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (114/114), 11.35 MiB | 13.58 MiB/s, done.\n",
            "Resolving deltas: 100% (42/42), done.\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets pandas transformers transformers[torch] scikit-multilearn optuna\n",
        "!git clone https://github.com/lucasadelino/thesis.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from google.colab import files\n",
        "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    BertForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    EvalPrediction,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from sklearn.metrics import f1_score, roc_auc_score, hamming_loss\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "# token_subgroup_single\n",
        "model_type = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
        "num_labels = 3\n",
        "label_format = \"maj_multi\"\n",
        "\n",
        "\n",
        "def id_array_to_labels(id_array):\n",
        "    \"\"\"Converts an array of indices to a bit array\n",
        "    e.g. the array [0, 2, 3, 4, 5] is converted to [1. 0. 1. 1. 1. 1. 0. 0. 0.]\"\"\"\n",
        "    labels = np.zeros(9)\n",
        "    labels[id_array] = 1\n",
        "    return labels.astype(float)\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels(example, single_label=True):\n",
        "\n",
        "    # Tokenize the sentence pair\n",
        "    tokenized_inputs = tokenizer(\n",
        "        example[\"sentence1_tokenized\"],\n",
        "        example[\"sentence2_tokenized\"],\n",
        "        padding=\"max_length\",\n",
        "        max_length=90,\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "\n",
        "    label_array_1 = example[\"s1_token_labs\"]  # Label array for the first sentence\n",
        "    label_array_2 = example[\"s2_token_labs\"]  # Label array for the second sentence\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=0)\n",
        "\n",
        "    label_ids = []\n",
        "    sentence_switch = False  # Flag to indicate when to switch from the first to the second sentence's labels\n",
        "    previous_word_id = None\n",
        "\n",
        "    if single_label:\n",
        "        pad_value = -100\n",
        "    else:\n",
        "        pad_value = [-100.] * num_labels\n",
        "\n",
        "    for index, word_id in enumerate(word_ids):\n",
        "        if word_id is None and not sentence_switch:\n",
        "            # First [CLS] or [SEP] token encountered\n",
        "            label_ids.append(pad_value)\n",
        "            if index > 0:\n",
        "                # First [SEP] token encountered\n",
        "                sentence_switch = True  # Switch to the second sentence's labels\n",
        "        elif word_id is None:\n",
        "            # Second [SEP] token or [CLS] token at the end\n",
        "            label_ids.append(pad_value)\n",
        "        else:\n",
        "            # Normal token, choose appropriate label array\n",
        "            current_label_array = label_array_2 if sentence_switch else label_array_1\n",
        "            label_ids.append(\n",
        "                current_label_array[word_id] if single_label else current_label_array[word_id].tolist()\n",
        "                )\n",
        "\n",
        "        previous_word_id = word_id\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = label_ids\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "def apply_tokenization(train_df, test_df, val_df, single_label=True):\n",
        "    \"Tokenize sentences and save as new column in dfs\"\n",
        "\n",
        "    train_df[\"tokenized_sentences\"] = train_df.apply(\n",
        "        tokenize_and_align_labels, single_label=single_label, axis=1\n",
        "        )\n",
        "    test_df[\"tokenized_sentences\"] = test_df.apply(\n",
        "        tokenize_and_align_labels, single_label=single_label, axis=1\n",
        "        )\n",
        "    val_df[\"tokenized_sentences\"] = val_df.apply(\n",
        "        tokenize_and_align_labels, single_label=single_label, axis=1\n",
        "        )\n",
        "\n",
        "    # Convert tokenized sentences to tensors. Those will be the inputs to our (PyTorch) model\n",
        "    train_df[\"inputs\"] = train_df[\"tokenized_sentences\"].apply(\n",
        "        lambda x: x.convert_to_tensors(\"pt\")\n",
        "    )\n",
        "    test_df[\"inputs\"] = test_df[\"tokenized_sentences\"].apply(\n",
        "        lambda x: x.convert_to_tensors(\"pt\")\n",
        "    )\n",
        "    val_df[\"inputs\"] = val_df[\"tokenized_sentences\"].apply(\n",
        "        lambda x: x.convert_to_tensors(\"pt\")\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    y_pred = [\n",
        "        p\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "        for p, l in zip(prediction, label)\n",
        "        if l != -100\n",
        "    ]\n",
        "    y_true = [l for label in labels for l in label if l != -100]\n",
        "\n",
        "    non_zero_labels = list(range(1, num_labels))\n",
        "\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n",
        "    accuracy = f1_score(\n",
        "        y_true, y_pred, average=\"micro\", labels=non_zero_labels\n",
        "    )\n",
        "    inflated_accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n",
        "    results = {\n",
        "        \"f1\": f1_micro_average,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"0accuracy\": inflated_accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "    }\n",
        "    return results\n",
        "\n",
        "\n",
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 3e-4, log=True),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 4, 8),\n",
        "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 10, 300),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.05, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32, 64, 128]),\n",
        "        \"seed\": trial.set_user_attr(\"seed\", 3)\n",
        "\n",
        "    }\n",
        "\n",
        "def model_init():\n",
        "    return BertForTokenClassification.from_pretrained(model_type, num_labels=num_labels)\n",
        "\n",
        "\n",
        "def get_accuracy(input):\n",
        "    return input[\"eval_accuracy\"]\n",
        "\n",
        "# Defining evaluation metrics\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def test_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    y_pred = [\n",
        "        p for prediction, label in zip(predictions, labels)\n",
        "        for p, l in zip(prediction, label) if l != -100\n",
        "    ]\n",
        "    y_true = [\n",
        "        l for label in labels\n",
        "        for l in label if l != -100\n",
        "    ]\n",
        "    labs = list(range(1, num_labels))\n",
        "    overall_f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro', labels=labs).tolist()\n",
        "    overall_f1_micro = f1_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs).tolist()\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "    precision_overall = precision_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs)\n",
        "    recall_overall = recall_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs)\n",
        "\n",
        "    #accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "    recall = recall_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "\n",
        "    results = {'F1': f1_micro_average,\n",
        "               'Overal F1 Macro': overall_f1_macro,\n",
        "               'Overall Accuracy': overall_f1_micro,\n",
        "               #'accuracy': accuracy,\n",
        "               'Precision': precision,\n",
        "               'Recall': recall,\n",
        "               'Precision Overall': precision_overall,\n",
        "               'Recall Overall': recall_overall}\n",
        "\n",
        "    return results\n",
        "\n",
        "def multilabel_test_metrics(predictions, labels, thresholds=[0.5] * num_labels):\n",
        "    thresholds = torch.Tensor(thresholds)\n",
        "    # First, apply sigmoid on predictions\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # Flatten probs and labels\n",
        "    # Originally of dims [batch_size, sequence_length, num_labels] to [batch_size * sequence_length, num_labels]\n",
        "    flat_probs = probs.view(-1, probs.shape[-1])\n",
        "    flat_labels = labels.reshape(-1, labels.shape[-1])\n",
        "\n",
        "    # Filter rows where all labels are -100\n",
        "    mask = ~(flat_labels == -100).all(axis=1)\n",
        "    filtered_probs = flat_probs[mask]\n",
        "    filtered_labels = flat_labels[mask]\n",
        "\n",
        "    # Generate predictions using threshold\n",
        "    y_pred = np.zeros(filtered_probs.shape)\n",
        "    y_pred[np.where(filtered_probs > thresholds)] = 1\n",
        "\n",
        "    y_true = filtered_labels\n",
        "\n",
        "    # Compute overall metrics\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    precision_overall = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    recall_overall = recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "    # Compute class-wise Precision, Recall, F1 Score\n",
        "    precision_classwise = precision_score(y_true, y_pred, average=None).tolist()\n",
        "    recall_classwise = recall_score(y_true, y_pred, average=None).tolist()\n",
        "    f1_classwise = f1_score(y_true, y_pred, average=None).tolist()\n",
        "\n",
        "    # Samples\n",
        "    f1_samples = f1_score(y_true, y_pred, average='samples').tolist()\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Return metrics in a dictionary\n",
        "    metrics = {\n",
        "        'f1': f1_micro_average,\n",
        "        'roc_auc': roc_auc,\n",
        "        'hamming_loss': hamming,\n",
        "        'precision_per_class': precision_classwise,\n",
        "        'recall_per_class': recall_classwise,\n",
        "        'f1_per_class': f1_classwise,\n",
        "        'f1_samples': f1_samples,\n",
        "        'accuracy': accuracy,\n",
        "        'precision_overall': precision_overall,\n",
        "        'recall_overall': recall_overall\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def subset_labels(df, label_format):\n",
        "    \"Returns a subset of df containing only labels according to label_format\"\n",
        "    assert label_format in [\"sub_single\", \"maj_single\", \"sub_multi\", \"maj_multi\"], \"Invalid label_format\"\n",
        "    new_df = df[['sentence1', 'sentence2', 'sentence1_tokenized', 'sentence2_tokenized', 'collapsed_labels',\n",
        "                f's1_token_labs_{label_format}', f's2_token_labs_{label_format}',]]\n",
        "    new_df.rename(columns={f's1_token_labs_{label_format}': 's1_token_labs',\n",
        "                            f's2_token_labs_{label_format}': 's2_token_labs',}, inplace=True)\n",
        "    return new_df\n",
        "\n",
        "def show_test_result(trainer, test_df):\n",
        "    test_result = trainer.predict(test['inputs'].values)\n",
        "\n",
        "    # Print default metrics collected during prediction\n",
        "    for item, value in test_result.metrics.items():\n",
        "        print(f\"{item}: {value}\")\n",
        "\n",
        "    predictions = torch.Tensor(test_result.predictions)\n",
        "    labels = torch.Tensor(test_result.label_ids)\n",
        "\n",
        "    # Compute class-wise metrics\n",
        "    #thresholds = [0.15, 0.5, 0.5, 0.5, 0.5, 0.19, 0.5, 0.5]\n",
        "    results = test_metrics((predictions, labels))\n",
        "    df = pd.DataFrame.from_dict(results)\n",
        "    #df.drop(columns = ['f1', 'roc_auc', 'hamming_loss'], inplace=True)\n",
        "    if num_labels == 4:\n",
        "        indices = [['1. Addition/Deletion', '2. Change of Order', '3. Substitution']]\n",
        "    else:\n",
        "        indices = [['1. Add/Del - Function Word', '2. Add/Del - Content Word', '3. Change of Order',\n",
        "             '4. Substitution - Synonym', '5. Substitution - Contextual Synonym', '6. Substitution - Morphological',\n",
        "             '7. Substitution - Spelling and Format', '8. Add/Del - Punctuation']]\n",
        "    df.index = indices\n",
        "    return df\n",
        "\n",
        "def show_multilabel_test_result(trainer, test_df):\n",
        "    test_result = trainer.predict(test['inputs'].values)\n",
        "\n",
        "    # Print default metrics collected during prediction\n",
        "    for item, value in test_result.metrics.items():\n",
        "        print(f\"{item}: {value}\")\n",
        "\n",
        "    predictions = torch.Tensor(test_result.predictions)\n",
        "    labels = torch.Tensor(test_result.label_ids)\n",
        "\n",
        "    # Compute class-wise metrics\n",
        "    #thresholds = [0.15, 0.5, 0.5, 0.5, 0.5, 0.19, 0.5, 0.5]\n",
        "    results = multilabel_test_metrics(predictions, labels)\n",
        "    df = pd.DataFrame.from_dict(results)\n",
        "    df.drop(columns = ['f1', 'roc_auc', 'hamming_loss'], inplace=True)\n",
        "    if num_labels == 3:\n",
        "        indices = [['1. Addition/Deletion', '2. Change of Order', '3. Substitution']]\n",
        "    else:\n",
        "        indices = [['1. Add/Del - Function Word', '2. Add/Del - Content Word', '3. Change of Order',\n",
        "             '4. Substitution - Synonym', '5. Substitution - Contextual Synonym', '6. Substitution - Morphological',\n",
        "             '7. Substitution - Spelling and Format', '8. Add/Del - Punctuation']]\n",
        "    df.index = indices\n",
        "    return df\n",
        "\n",
        "class MultiLabelTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights = None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if class_weights is not None:\n",
        "            class_weights = class_weights.to(self.args.device)\n",
        "            #logging.info(f\"Using multi-label classification with class weights\", class_weights)\n",
        "        self.loss_fct = BCEWithLogitsLoss(weight=class_weights)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        \"\"\"\n",
        "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
        "        Subclass and override for custom behavior.\n",
        "        \"\"\"\n",
        "        labels  = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # this simultaneously accesses predictions for tokens that aren't CLS or PAD\n",
        "        # and flattens the logits or labels\n",
        "        flat_outputs = outputs.logits[labels!=-100]\n",
        "        flat_labels  = labels[labels!=-100]\n",
        "\n",
        "        try:\n",
        "            loss = self.loss_fct(flat_outputs, flat_labels.float())\n",
        "        except AttributeError:  # DataParallel\n",
        "            loss = self.loss_fct(flat_outputs, flat_labels.float())\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def multilabel_metrics(predictions, labels, threshold=0.5):\n",
        "    # First, apply sigmoid on predictions\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # Flatten probs and labels\n",
        "    # Originally of dims [batch_size, sequence_length, num_labels] to [batch_size * sequence_length, num_labels]\n",
        "    flat_probs = probs.view(-1, probs.shape[-1])\n",
        "    flat_labels = labels.reshape(-1, labels.shape[-1])\n",
        "\n",
        "    # Filter rows where all labels are -100\n",
        "    mask = ~(flat_labels == -100).all(axis=1)\n",
        "    filtered_probs = flat_probs[mask]\n",
        "    filtered_labels = flat_labels[mask]\n",
        "\n",
        "    # Generate predictions using threshold\n",
        "    y_pred = np.zeros(filtered_probs.shape)\n",
        "    y_pred[np.where(filtered_probs > threshold)] = 1\n",
        "\n",
        "    # Now we can compute metrics:\n",
        "    y_true = filtered_labels\n",
        "    #print(y_true)\n",
        "    #print(y_pred)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'hamming loss': hamming}\n",
        "    return metrics\n",
        "\n",
        "def compute_multilabel_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    result = multilabel_metrics(predictions=preds, labels=p.label_ids)\n",
        "    return result"
      ],
      "metadata": {
        "id": "Kijc__GJ2aWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle('thesis/datasets/etpc_reannotated.pkl')\n",
        "data = subset_labels(data, label_format)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "1EhDYHKLgdgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "08753e44-206b-4842-bcb1-fd9a2d76502e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-e12063aba532>:259: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df.rename(columns={f's1_token_labs_{label_format}': 's1_token_labs',\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentence1  \\\n",
              "0  Amrozi accused his brother, whom he called \"th...   \n",
              "2  They had published an advertisement on the Int...   \n",
              "4  The stock rose $2.11, or about 11 percent, to ...   \n",
              "5  Revenue in the first quarter of the year dropp...   \n",
              "7  The DVD-CCA then appealed to the state Supreme...   \n",
              "\n",
              "                                           sentence2  \\\n",
              "0  Referring to him as only \"the witness\", Amrozi...   \n",
              "2  On June 10, the ship's owners had published an...   \n",
              "4  PG&E Corp. shares jumped $1.63 or 8 percent to...   \n",
              "5  With the scandal hanging over Stewart's compan...   \n",
              "7  The DVD CCA appealed that decision to the U.S....   \n",
              "\n",
              "                                 sentence1_tokenized  \\\n",
              "0  [Amrozi, accused, his, brother, ,, whom, he, c...   \n",
              "2  [They, had, published, an, advertisement, on, ...   \n",
              "4  [The, stock, rose, $, 2.11, ,, or, about, 11, ...   \n",
              "5  [Revenue, in, the, first, quarter, of, the, ye...   \n",
              "7  [The, DVD-CCA, then, appealed, to, the, state,...   \n",
              "\n",
              "                                 sentence2_tokenized       collapsed_labels  \\\n",
              "0  [Referring, to, him, as, only, ``, the, witnes...           [0, 2, 3, 4]   \n",
              "2  [On, June, 10, ,, the, ship, 's, owners, had, ...        [0, 2, 3, 4, 5]   \n",
              "4  [PG, &, E, Corp., shares, jumped, $, 1.63, or,...  [0, 1, 2, 3, 4, 5, 8]   \n",
              "5  [With, the, scandal, hanging, over, Stewart, '...              [0, 1, 2]   \n",
              "7  [The, DVD, CCA, appealed, that, decision, to, ...        [0, 1, 2, 4, 7]   \n",
              "\n",
              "                                       s1_token_labs  \\\n",
              "0  [[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...   \n",
              "2  [[0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, ...   \n",
              "4  [[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...   \n",
              "5  [[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, ...   \n",
              "7  [[0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...   \n",
              "\n",
              "                                       s2_token_labs  \n",
              "0  [[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...  \n",
              "2  [[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...  \n",
              "4  [[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...  \n",
              "5  [[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, ...  \n",
              "7  [[0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ca405774-c6fd-4719-94ee-2cb722bb7092\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>collapsed_labels</th>\n",
              "      <th>s1_token_labs</th>\n",
              "      <th>s2_token_labs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
              "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
              "      <td>[Amrozi, accused, his, brother, ,, whom, he, c...</td>\n",
              "      <td>[Referring, to, him, as, only, ``, the, witnes...</td>\n",
              "      <td>[0, 2, 3, 4]</td>\n",
              "      <td>[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...</td>\n",
              "      <td>[[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They had published an advertisement on the Int...</td>\n",
              "      <td>On June 10, the ship's owners had published an...</td>\n",
              "      <td>[They, had, published, an, advertisement, on, ...</td>\n",
              "      <td>[On, June, 10, ,, the, ship, 's, owners, had, ...</td>\n",
              "      <td>[0, 2, 3, 4, 5]</td>\n",
              "      <td>[[0.0, 0.0, 1.0], [0.0, 0.0, 0.0], [0.0, 0.0, ...</td>\n",
              "      <td>[[0.0, 1.0, 0.0], [0.0, 1.0, 0.0], [0.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
              "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
              "      <td>[The, stock, rose, $, 2.11, ,, or, about, 11, ...</td>\n",
              "      <td>[PG, &amp;, E, Corp., shares, jumped, $, 1.63, or,...</td>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 8]</td>\n",
              "      <td>[[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...</td>\n",
              "      <td>[[0.0, 0.0, 1.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Revenue in the first quarter of the year dropp...</td>\n",
              "      <td>With the scandal hanging over Stewart's compan...</td>\n",
              "      <td>[Revenue, in, the, first, quarter, of, the, ye...</td>\n",
              "      <td>[With, the, scandal, hanging, over, Stewart, '...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [0.0, 0.0, ...</td>\n",
              "      <td>[[1.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
              "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
              "      <td>[The, DVD-CCA, then, appealed, to, the, state,...</td>\n",
              "      <td>[The, DVD, CCA, appealed, that, decision, to, ...</td>\n",
              "      <td>[0, 1, 2, 4, 7]</td>\n",
              "      <td>[[0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [1.0, 0.0, ...</td>\n",
              "      <td>[[0.0, 0.0, 0.0], [0.0, 0.0, 1.0], [0.0, 0.0, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ca405774-c6fd-4719-94ee-2cb722bb7092')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ca405774-c6fd-4719-94ee-2cb722bb7092 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ca405774-c6fd-4719-94ee-2cb722bb7092');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-646b64a4-8564-4dd4-8831-c3d73a40d7b7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-646b64a4-8564-4dd4-8831-c3d73a40d7b7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-646b64a4-8564-4dd4-8831-c3d73a40d7b7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3900,\n  \"fields\": [\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3899,\n        \"samples\": [\n          \"He said it was a mistake, and he reimbursed the party nearly $2,000.\",\n          \"Illinois State Police accident reconstruction experts were investigating the cause.\",\n          \"\\\"This deal makes sense for both companies,\\\" Brian Halla, National's chief executive, said in a statement.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3743,\n        \"samples\": [\n          \"Hidalgo County Judge Ramon Garcia says when he was growing up, he wasn't allowed to speak Spanish at school.\",\n          \"A judge already has ruled that double-jeopardy protections don't apply in the case.\",\n          \"The test, in four sections, includes algebra and geometry, along with some questions on probability and statistics.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1_tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2_tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"collapsed_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s1_token_labs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s2_token_labs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "kqtLGzqznnkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split"
      ],
      "metadata": {
        "id": "AZDrpicG-ref"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indices selected for each set\n",
        "# It's easier to just use indices rather than having to deal with sentence pairs here\n",
        "indices = np.array(data.index.tolist())\n",
        "indices = np.expand_dims(indices, axis=1)\n",
        "indices.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrVubcZz3Hfw",
        "outputId": "0d291883-c82e-4348-afaf-726985b748fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3900, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels, converted\n",
        "labels = data['collapsed_labels'].values\n",
        "labels = [id_array_to_labels(each_list) for each_list in labels]\n",
        "data['labels'] = labels\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "lgD8GTCj8s7Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratification"
      ],
      "metadata": {
        "id": "oVBOtnlCNX5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ITERATIVE STRATIFICATION\n",
        "np.random.seed(3)\n",
        "# 80/20 split into train and temp sets (temp set will be further split below)\n",
        "x_train, y_train, x_val_test, y_val_test = iterative_train_test_split(indices, labels, test_size=0.2)\n",
        "# 50/50 split temp set into validation and test sets\n",
        "x_val, y_val, x_test, y_test  = iterative_train_test_split(x_val_test, y_val_test, test_size=0.5)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9864a902-3624-437d-d3a2-23f56fe37167",
        "id": "k5S-zwgn-phE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3087, 1)\n",
            "(414, 1)\n",
            "(399, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting indices in x matrices back to 1-d\n",
        "indices_train = np.squeeze(x_train)\n",
        "indices_test = np.squeeze(x_test)\n",
        "indices_val = np.squeeze(x_val)"
      ],
      "metadata": {
        "id": "IAudX1V_-phF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.loc[indices_train, :]\n",
        "test = data.loc[indices_test, :]\n",
        "val = data.loc[indices_val, :]"
      ],
      "metadata": {
        "id": "HOFC-iMo-phF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing"
      ],
      "metadata": {
        "id": "bas61Dh4mg3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apply_tokenization(train, test, val, single_label=False)"
      ],
      "metadata": {
        "id": "5OZq3CvvFCRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "s5FqLYjal3WU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {'learning_rate': 2.367719983396521e-05, 'num_train_epochs': 7, 'warmup_steps': 78, 'weight_decay': 0.03871726302598747, 'per_device_train_batch_size': 8}\n",
        "metric_name = \"f1\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"bert-paraop\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    logging_steps = 10,\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=params['learning_rate'],\n",
        "    per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "    per_device_eval_batch_size=params['per_device_train_batch_size'],\n",
        "    num_train_epochs=params['num_train_epochs'],\n",
        "    warmup_steps=params['warmup_steps'],\n",
        "    weight_decay=params['weight_decay'],\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=2,\n",
        "    metric_for_best_model=metric_name,\n",
        "    seed=3\n",
        ")\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "trainer = MultiLabelTrainer(\n",
        "    model=None,\n",
        "    args=args,\n",
        "    train_dataset=train['inputs'].values,\n",
        "    eval_dataset=val['inputs'].values,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_multilabel_metrics,\n",
        "    model_init=model_init\n",
        ")\n",
        "\n",
        "def f1(input):\n",
        "    return input['eval_f1']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "faef9f1cb024473194827ce7daeacc3c",
            "16d4e115a0194911b895f3e04951cdd8",
            "746e40882e54461aa3fff2ce7ac065ff",
            "f91e5fca2cf3451caecaf6b68763f0f4",
            "fb6352207a854f398db79d66c79bc1eb",
            "14fe591ab71f4d7dba5424ea416c73f9",
            "74468f91f21c4df0a5fa6da4ff681282",
            "348aa42f0a3948f18e9f41e2f3001b2a",
            "4d4d6ce36a1442c294630ed750363d6e",
            "9d364b6cd0174b73b21bccc494552fa8",
            "465ad1d9f43d4bc9870480b5170ceca3"
          ]
        },
        "id": "_aO19wa9G3ih",
        "outputId": "47b8206e-edfd-4e7e-e458-e19264444906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "faef9f1cb024473194827ce7daeacc3c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "vH3Szm8PKXzl",
        "outputId": "02e333a8-69a9-42ce-980d-2ce5028f1d98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2702' max='2702' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2702/2702 04:44, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Roc Auc</th>\n",
              "      <th>Hamming loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.189000</td>\n",
              "      <td>0.176469</td>\n",
              "      <td>0.551110</td>\n",
              "      <td>0.721952</td>\n",
              "      <td>0.065798</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.184300</td>\n",
              "      <td>0.155314</td>\n",
              "      <td>0.604024</td>\n",
              "      <td>0.757670</td>\n",
              "      <td>0.061330</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.121800</td>\n",
              "      <td>0.158818</td>\n",
              "      <td>0.627321</td>\n",
              "      <td>0.773348</td>\n",
              "      <td>0.058843</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.106100</td>\n",
              "      <td>0.169232</td>\n",
              "      <td>0.636613</td>\n",
              "      <td>0.784112</td>\n",
              "      <td>0.058905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.077000</td>\n",
              "      <td>0.169428</td>\n",
              "      <td>0.648585</td>\n",
              "      <td>0.800917</td>\n",
              "      <td>0.059473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.075600</td>\n",
              "      <td>0.177444</td>\n",
              "      <td>0.639852</td>\n",
              "      <td>0.791543</td>\n",
              "      <td>0.059795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.066700</td>\n",
              "      <td>0.181027</td>\n",
              "      <td>0.642963</td>\n",
              "      <td>0.792194</td>\n",
              "      <td>0.059043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2702, training_loss=0.1301419171115189, metrics={'train_runtime': 286.4767, 'train_samples_per_second': 75.43, 'train_steps_per_second': 9.432, 'total_flos': 992533476220020.0, 'train_loss': 0.1301419171115189, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "I_xrhbN3iKRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = trainer.evaluate()\n",
        "for item, value in eval_result.items():\n",
        "    print(f\"{item}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "o3iUk7UOFzRi",
        "outputId": "f55c06f3-0ecf-46f7-f079-f66f81487991"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='52' max='52' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [52/52 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval_loss: 0.16942796111106873\n",
            "eval_f1: 0.6485849056603774\n",
            "eval_roc_auc: 0.8009168210017643\n",
            "eval_hamming loss: 0.05947281966256774\n",
            "eval_runtime: 1.096\n",
            "eval_samples_per_second: 377.743\n",
            "eval_steps_per_second: 47.446\n",
            "epoch: 7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "GRAtLcULHwzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_multilabel_test_result(trainer, test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "TXaoD6U2POB1",
        "outputId": "956a1c40-7c82-4ea1-b800-4df25f1827f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss: 0.1862102448940277\n",
            "test_f1: 0.6625010847869478\n",
            "test_roc_auc: 0.7991621949025983\n",
            "test_hamming loss: 0.06382420035120542\n",
            "test_runtime: 1.0439\n",
            "test_samples_per_second: 382.232\n",
            "test_steps_per_second: 47.899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1760: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no true nor predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      precision_per_class  recall_per_class  f1_per_class  \\\n",
              "1. Addition/Deletion             0.770734          0.707222      0.737614   \n",
              "2. Change of Order               0.621387          0.446985      0.519952   \n",
              "3. Substitution                  0.674126          0.631510      0.652122   \n",
              "\n",
              "                      f1_samples  accuracy  precision_overall  recall_overall  \n",
              "1. Addition/Deletion    0.187731  0.832751            0.70101        0.628003  \n",
              "2. Change of Order      0.187731  0.832751            0.70101        0.628003  \n",
              "3. Substitution         0.187731  0.832751            0.70101        0.628003  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-98864a31-b5dd-4886-a867-79f65a306784\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>precision_per_class</th>\n",
              "      <th>recall_per_class</th>\n",
              "      <th>f1_per_class</th>\n",
              "      <th>f1_samples</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision_overall</th>\n",
              "      <th>recall_overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1. Addition/Deletion</th>\n",
              "      <td>0.770734</td>\n",
              "      <td>0.707222</td>\n",
              "      <td>0.737614</td>\n",
              "      <td>0.187731</td>\n",
              "      <td>0.832751</td>\n",
              "      <td>0.70101</td>\n",
              "      <td>0.628003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2. Change of Order</th>\n",
              "      <td>0.621387</td>\n",
              "      <td>0.446985</td>\n",
              "      <td>0.519952</td>\n",
              "      <td>0.187731</td>\n",
              "      <td>0.832751</td>\n",
              "      <td>0.70101</td>\n",
              "      <td>0.628003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3. Substitution</th>\n",
              "      <td>0.674126</td>\n",
              "      <td>0.631510</td>\n",
              "      <td>0.652122</td>\n",
              "      <td>0.187731</td>\n",
              "      <td>0.832751</td>\n",
              "      <td>0.70101</td>\n",
              "      <td>0.628003</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-98864a31-b5dd-4886-a867-79f65a306784')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-98864a31-b5dd-4886-a867-79f65a306784 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-98864a31-b5dd-4886-a867-79f65a306784');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-0992e2cb-a54f-4d15-987d-35d15184c6d7\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0992e2cb-a54f-4d15-987d-35d15184c6d7')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-0992e2cb-a54f-4d15-987d-35d15184c6d7 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"show_multilabel_test_result(trainer, test)\",\n  \"rows\": 3,\n  \"fields\": [\n    {\n      \"column\": \"precision_per_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07573976340633086,\n        \"min\": 0.6213872832369942,\n        \"max\": 0.7707342842049657,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7707342842049657,\n          0.6213872832369942,\n          0.6741258741258741\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall_per_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13385627195187633,\n        \"min\": 0.446985446985447,\n        \"max\": 0.707222491517208,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.707222491517208,\n          0.446985446985447,\n          0.6315099901735998\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_per_class\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10966212112747983,\n        \"min\": 0.5199516324062877,\n        \"max\": 0.7376137512639029,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          0.7376137512639029,\n          0.5199516324062877,\n          0.65212244207678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"f1_samples\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.18773078627344789,\n        \"max\": 0.18773078627344789,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.18773078627344789\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.3597399555105182e-16,\n        \"min\": 0.8327507262074738,\n        \"max\": 0.8327507262074738,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.8327507262074738\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"precision_overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.701010101010101,\n        \"max\": 0.701010101010101,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.701010101010101\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"recall_overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.6280026324448832,\n        \"max\": 0.6280026324448832,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6280026324448832\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Hyperparameter Search"
      ],
      "metadata": {
        "id": "CWRJjm6AStsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_trials = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    hp_space=optuna_hp_space,\n",
        "    n_trials=15,\n",
        "    compute_objective=get_accuracy\n",
        ")"
      ],
      "metadata": {
        "id": "LRIiLcRBdy_o",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e4e3de90-4430-458c-ed27-7cf2377abbb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-08-01 23:04:29,453] A new study created in memory with name: no-name-6ae1f40d-91a1-4435-9a62-480a4441911a\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='125' max='125' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [125/125 01:57, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.037700</td>\n",
              "      <td>0.802727</td>\n",
              "      <td>0.628894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.739603</td>\n",
              "      <td>0.547013</td>\n",
              "      <td>0.739603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.730200</td>\n",
              "      <td>0.575984</td>\n",
              "      <td>0.774364</td>\n",
              "      <td>0.453159</td>\n",
              "      <td>0.796021</td>\n",
              "      <td>0.755583</td>\n",
              "      <td>0.796021</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.580600</td>\n",
              "      <td>0.510594</td>\n",
              "      <td>0.801866</td>\n",
              "      <td>0.548438</td>\n",
              "      <td>0.821305</td>\n",
              "      <td>0.795793</td>\n",
              "      <td>0.821305</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.454600</td>\n",
              "      <td>0.459336</td>\n",
              "      <td>0.822911</td>\n",
              "      <td>0.596686</td>\n",
              "      <td>0.822503</td>\n",
              "      <td>0.824289</td>\n",
              "      <td>0.822503</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.370700</td>\n",
              "      <td>0.471696</td>\n",
              "      <td>0.830280</td>\n",
              "      <td>0.612268</td>\n",
              "      <td>0.838668</td>\n",
              "      <td>0.829780</td>\n",
              "      <td>0.838668</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-08-01 23:06:30,513] Trial 0 finished with value: 0.6122684074109628 and parameters: {'learning_rate': 0.0001148646311538582, 'num_train_epochs': 5, 'warmup_steps': 130, 'weight_decay': 0.012740828164462818, 'per_device_train_batch_size': 128}. Best is trial 0 with value: 0.6122684074109628.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='903' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 903/1544 01:32 < 01:05, 9.74 it/s, Epoch 2.34/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.493300</td>\n",
              "      <td>0.502941</td>\n",
              "      <td>0.808001</td>\n",
              "      <td>0.558203</td>\n",
              "      <td>0.830194</td>\n",
              "      <td>0.808801</td>\n",
              "      <td>0.830194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.424900</td>\n",
              "      <td>0.416505</td>\n",
              "      <td>0.843796</td>\n",
              "      <td>0.651714</td>\n",
              "      <td>0.846175</td>\n",
              "      <td>0.842492</td>\n",
              "      <td>0.846175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[W 2024-08-01 23:08:04,052] Trial 1 failed with parameters: {'learning_rate': 4.5916782139053155e-05, 'num_train_epochs': 4, 'warmup_steps': 177, 'weight_decay': 0.019537492806101862, 'per_device_train_batch_size': 8} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\", line 196, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\", line 211, in _objective\n",
            "    trainer.train(resume_from_checkpoint=checkpoint, trial=trial)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 1932, in train\n",
            "    return inner_training_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\", line 2273, in _inner_training_loop\n",
            "    and (torch.isnan(tr_loss_step) or torch.isinf(tr_loss_step))\n",
            "KeyboardInterrupt\n",
            "[W 2024-08-01 23:08:04,053] Trial 1 failed with value None.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-553750dd84d2>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m }\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m best_trials = trainer.hyperparameter_search(\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"maximize\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mbackend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"optuna\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mhyperparameter_search\u001b[0;34m(self, hp_space, compute_objective, n_trials, direction, backend, hp_name, **kwargs)\u001b[0m\n\u001b[1;32m   3204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_objective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault_compute_objective\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompute_objective\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcompute_objective\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m         \u001b[0mbest_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_search_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/hyperparameter_search.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrun_hp_search_optuna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdefault_hp_space\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36mrun_hp_search_optuna\u001b[0;34m(trainer, n_trials, direction, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0mdirection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdirections\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mdirection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0mstudy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdirections\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdirections\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_multi_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0mbest_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/study.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0mIf\u001b[0m \u001b[0mnested\u001b[0m \u001b[0minvocation\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0moccurs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \"\"\"\n\u001b[0;32m--> 451\u001b[0;31m         _optimize(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mstudy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             _optimize_sequential(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 159\u001b[0;31m             \u001b[0mfrozen_trial\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_run_trial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstudy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    160\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;31m# The following line mitigates memory problems that can be occurred in some\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    245\u001b[0m         \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m     ):\n\u001b[0;32m--> 247\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfunc_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfrozen_trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/optuna/study/_optimize.py\u001b[0m in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mget_heartbeat_thread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstudy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mvalue_or_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0;31m# TODO(mamu): Handle multi-objective cases.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/integrations/integration_utils.py\u001b[0m in \u001b[0;36m_objective\u001b[0;34m(trial, checkpoint_dir)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0;31m# If there hasn't been any evaluation during the training loop.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1931\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1932\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1933\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1934\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2271\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2272\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2274\u001b[0m                 ):\n\u001b[1;32m   2275\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLYVAJvgEpyc",
        "outputId": "e38abbc0-11a0-4cf5-8ee1-46b2de0ad65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='1', objective=0.6022401184856059, hyperparameters={'learning_rate': 0.00021437583926908025, 'num_train_epochs': 7, 'warmup_steps': 261, 'weight_decay': 0.03953905927366381, 'per_device_train_batch_size': 16}, run_summary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ]
    }
  ]
}