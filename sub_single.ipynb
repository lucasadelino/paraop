{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "CWRJjm6AStsW"
      ],
      "machine_shape": "hm",
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c722d5ae94134acf9e6fd5dc55a291c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b22284565924259b99a155f59225a45",
              "IPY_MODEL_e7eb5820d46d4d3196f0d9e0740b8615",
              "IPY_MODEL_9d5832b236d1442fb550b7d6a6bf4d21"
            ],
            "layout": "IPY_MODEL_68d40f3419f148c6a192e2f212c39954"
          }
        },
        "1b22284565924259b99a155f59225a45": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_92cb9edf2b7d41f188e56c83d3ed76eb",
            "placeholder": "​",
            "style": "IPY_MODEL_4ae9d623030a436aaeb06d1deee96c5d",
            "value": "model.safetensors: 100%"
          }
        },
        "e7eb5820d46d4d3196f0d9e0740b8615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12f174afef2845e0a90a8991729e61d9",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ac4b9a16ad74b84a7bc9617d7ca14b7",
            "value": 440449768
          }
        },
        "9d5832b236d1442fb550b7d6a6bf4d21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bfc1949187b4346952bff456fa890ca",
            "placeholder": "​",
            "style": "IPY_MODEL_10e6be8be134487e9218907a1a665634",
            "value": " 440M/440M [00:01&lt;00:00, 456MB/s]"
          }
        },
        "68d40f3419f148c6a192e2f212c39954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92cb9edf2b7d41f188e56c83d3ed76eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ae9d623030a436aaeb06d1deee96c5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "12f174afef2845e0a90a8991729e61d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ac4b9a16ad74b84a7bc9617d7ca14b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8bfc1949187b4346952bff456fa890ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10e6be8be134487e9218907a1a665634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Reading Files"
      ],
      "metadata": {
        "id": "LzbzljFengh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets pandas transformers transformers[torch] scikit-multilearn optuna\n",
        "!git clone https://github.com/lucasadelino/thesis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lw0FxbQleFU",
        "outputId": "cdacf769-15b7-44a9-8d6d-f63ce7b8fabc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.42.4)\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.5.0,>=2023.1.0 (from fsspec[http]<=2024.5.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.32.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.3.1+cu121)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: triton==2.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.3.1)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.6.20-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-multilearn, xxhash, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, fsspec, dill, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, alembic, optuna, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.6.1\n",
            "    Uninstalling fsspec-2024.6.1:\n",
            "      Successfully uninstalled fsspec-2024.6.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "gcsfs 2024.6.1 requires fsspec==2024.6.1, but you have fsspec 2024.5.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.2 colorlog-6.8.2 datasets-2.20.0 dill-0.3.8 fsspec-2024.5.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.20 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 pyarrow-17.0.0 requests-2.32.3 scikit-multilearn-0.2.0 xxhash-3.4.1\n",
            "Cloning into 'thesis'...\n",
            "remote: Enumerating objects: 130, done.\u001b[K\n",
            "remote: Counting objects: 100% (130/130), done.\u001b[K\n",
            "remote: Compressing objects: 100% (92/92), done.\u001b[K\n",
            "Receiving objects: 100% (130/130), 11.36 MiB | 10.68 MiB/s, done.\n",
            "remote: Total 130 (delta 46), reused 115 (delta 31), pack-reused 0\u001b[K\n",
            "Resolving deltas: 100% (46/46), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from google.colab import files\n",
        "from torch.nn.modules.loss import BCEWithLogitsLoss\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    BertTokenizer,\n",
        "    BertForSequenceClassification,\n",
        "    BertForTokenClassification,\n",
        "    DataCollatorForTokenClassification,\n",
        "    EvalPrediction,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from sklearn.metrics import f1_score, roc_auc_score, hamming_loss\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import (\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    precision_recall_fscore_support,\n",
        "    accuracy_score,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "# token_subgroup_single\n",
        "model_type = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
        "num_labels = 9\n",
        "label_format = \"sub_single\"\n",
        "\n",
        "\n",
        "def id_array_to_labels(id_array):\n",
        "    \"\"\"Converts an array of indices to a bit array\n",
        "    e.g. the array [0, 2, 3, 4, 5] is converted to [1. 0. 1. 1. 1. 1. 0. 0. 0.]\"\"\"\n",
        "    labels = np.zeros(9)\n",
        "    labels[id_array] = 1\n",
        "    return labels.astype(float)\n",
        "\n",
        "\n",
        "def tokenize_and_align_labels(example, single_label=True):\n",
        "\n",
        "    # Tokenize the sentence pair\n",
        "    tokenized_inputs = tokenizer(\n",
        "        example[\"sentence1_tokenized\"],\n",
        "        example[\"sentence2_tokenized\"],\n",
        "        padding=\"max_length\",\n",
        "        max_length=90,\n",
        "        truncation=True,\n",
        "        is_split_into_words=True,\n",
        "    )\n",
        "\n",
        "    label_array_1 = example[\"s1_token_labs\"]  # Label array for the first sentence\n",
        "    label_array_2 = example[\"s2_token_labs\"]  # Label array for the second sentence\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=0)\n",
        "\n",
        "    label_ids = []\n",
        "    sentence_switch = False  # Flag to indicate when to switch from the first to the second sentence's labels\n",
        "    previous_word_id = None\n",
        "\n",
        "    if single_label:\n",
        "        pad_value = -100\n",
        "    else:\n",
        "        pad_value = [-100.] * num_labels\n",
        "\n",
        "    for index, word_id in enumerate(word_ids):\n",
        "        if word_id is None and not sentence_switch:\n",
        "            # First [CLS] or [SEP] token encountered\n",
        "            label_ids.append(pad_value)\n",
        "            if index > 0:\n",
        "                # First [SEP] token encountered\n",
        "                sentence_switch = True  # Switch to the second sentence's labels\n",
        "        elif word_id is None:\n",
        "            # Second [SEP] token or [CLS] token at the end\n",
        "            label_ids.append(pad_value)\n",
        "        else:\n",
        "            # Normal token, choose appropriate label array\n",
        "            current_label_array = label_array_2 if sentence_switch else label_array_1\n",
        "            label_ids.append(\n",
        "                current_label_array[word_id] if single_label else current_label_array[word_id].tolist()\n",
        "                )\n",
        "\n",
        "        previous_word_id = word_id\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = label_ids\n",
        "\n",
        "    return tokenized_inputs\n",
        "\n",
        "\n",
        "def apply_tokenization(train_df, test_df, val_df, single_label=True):\n",
        "    \"Tokenize sentences and save as new column in dfs\"\n",
        "\n",
        "    train_df[\"tokenized_sentences\"] = train_df.apply(\n",
        "        tokenize_and_align_labels, single_label=single_label, axis=1\n",
        "        )\n",
        "    test_df[\"tokenized_sentences\"] = test_df.apply(\n",
        "        tokenize_and_align_labels, single_label=single_label, axis=1\n",
        "        )\n",
        "    val_df[\"tokenized_sentences\"] = val_df.apply(\n",
        "        tokenize_and_align_labels, single_label=single_label, axis=1\n",
        "        )\n",
        "\n",
        "    # Convert tokenized sentences to tensors. Those will be the inputs to our (PyTorch) model\n",
        "    train_df[\"inputs\"] = train_df[\"tokenized_sentences\"].apply(\n",
        "        lambda x: x.convert_to_tensors(\"pt\")\n",
        "    )\n",
        "    test_df[\"inputs\"] = test_df[\"tokenized_sentences\"].apply(\n",
        "        lambda x: x.convert_to_tensors(\"pt\")\n",
        "    )\n",
        "    val_df[\"inputs\"] = val_df[\"tokenized_sentences\"].apply(\n",
        "        lambda x: x.convert_to_tensors(\"pt\")\n",
        "    )\n",
        "\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    y_pred = [\n",
        "        p\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "        for p, l in zip(prediction, label)\n",
        "        if l != -100\n",
        "    ]\n",
        "    y_true = [l for label in labels for l in label if l != -100]\n",
        "\n",
        "    non_zero_labels = list(range(1, num_labels))\n",
        "\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n",
        "    accuracy = f1_score(\n",
        "        y_true, y_pred, average=\"micro\", labels=non_zero_labels\n",
        "    )\n",
        "    inflated_accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n",
        "    recall = recall_score(y_true=y_true, y_pred=y_pred, average=\"weighted\")\n",
        "    results = {\n",
        "        \"f1\": f1_micro_average,\n",
        "        \"accuracy\": accuracy,\n",
        "        \"0accuracy\": inflated_accuracy,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "    }\n",
        "    return results\n",
        "\n",
        "\n",
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 3e-4, log=True),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 4, 8),\n",
        "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 10, 300),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.05, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32, 64, 128]),\n",
        "        \"seed\": trial.set_user_attr(\"seed\", 3)\n",
        "\n",
        "    }\n",
        "\n",
        "def model_init():\n",
        "    return BertForTokenClassification.from_pretrained(model_type, num_labels=num_labels)\n",
        "\n",
        "\n",
        "def get_accuracy(input):\n",
        "    return input[\"eval_accuracy\"]\n",
        "\n",
        "# Defining evaluation metrics\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def test_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    y_pred = [\n",
        "        p for prediction, label in zip(predictions, labels)\n",
        "        for p, l in zip(prediction, label) if l != -100\n",
        "    ]\n",
        "    y_true = [\n",
        "        l for label in labels\n",
        "        for l in label if l != -100\n",
        "    ]\n",
        "    labs = list(range(1, num_labels))\n",
        "    overall_f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro', labels=labs).tolist()\n",
        "    overall_f1_micro = f1_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs).tolist()\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "    precision_overall = precision_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs)\n",
        "    recall_overall = recall_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs)\n",
        "\n",
        "    #accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "    recall = recall_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "\n",
        "    results = {'F1': f1_micro_average,\n",
        "               'Overal F1 Macro': overall_f1_macro,\n",
        "               'Overall Accuracy': overall_f1_micro,\n",
        "               #'accuracy': accuracy,\n",
        "               'Precision': precision,\n",
        "               'Recall': recall,\n",
        "               'Precision Overall': precision_overall,\n",
        "               'Recall Overall': recall_overall}\n",
        "\n",
        "    return results\n",
        "\n",
        "def multilabel_test_metrics(predictions, labels, thresholds=[0.5] * num_labels):\n",
        "    thresholds = torch.Tensor(thresholds)\n",
        "    # First, apply sigmoid on predictions\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # Flatten probs and labels\n",
        "    # Originally of dims [batch_size, sequence_length, num_labels] to [batch_size * sequence_length, num_labels]\n",
        "    flat_probs = probs.view(-1, probs.shape[-1])\n",
        "    flat_labels = labels.reshape(-1, labels.shape[-1])\n",
        "\n",
        "    # Filter rows where all labels are -100\n",
        "    mask = ~(flat_labels == -100).all(axis=1)\n",
        "    filtered_probs = flat_probs[mask]\n",
        "    filtered_labels = flat_labels[mask]\n",
        "\n",
        "    # Generate predictions using threshold\n",
        "    y_pred = np.zeros(filtered_probs.shape)\n",
        "    y_pred[np.where(filtered_probs > thresholds)] = 1\n",
        "\n",
        "    y_true = filtered_labels\n",
        "\n",
        "    # Compute overall metrics\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    precision_overall = precision_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    recall_overall = recall_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "\n",
        "    # Compute class-wise Precision, Recall, F1 Score\n",
        "    precision_classwise = precision_score(y_true, y_pred, average=None).tolist()\n",
        "    recall_classwise = recall_score(y_true, y_pred, average=None).tolist()\n",
        "    f1_classwise = f1_score(y_true, y_pred, average=None).tolist()\n",
        "\n",
        "    # Samples\n",
        "    f1_samples = f1_score(y_true, y_pred, average='samples').tolist()\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "\n",
        "    # Return metrics in a dictionary\n",
        "    metrics = {\n",
        "        'f1': f1_micro_average,\n",
        "        'roc_auc': roc_auc,\n",
        "        'hamming_loss': hamming,\n",
        "        'precision_per_class': precision_classwise,\n",
        "        'recall_per_class': recall_classwise,\n",
        "        'f1_per_class': f1_classwise,\n",
        "        'f1_samples': f1_samples,\n",
        "        'accuracy': accuracy,\n",
        "        'precision_overall': precision_overall,\n",
        "        'recall_overall': recall_overall\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "def subset_labels(df, label_format):\n",
        "    \"Returns a subset of df containing only labels according to label_format\"\n",
        "    assert label_format in [\"sub_single\", \"maj_single\", \"sub_multi\", \"maj_multi\"], \"Invalid label_format\"\n",
        "    new_df = df[['sentence1', 'sentence2', 'sentence1_tokenized', 'sentence2_tokenized', 'collapsed_labels',\n",
        "                f's1_token_labs_{label_format}', f's2_token_labs_{label_format}',]]\n",
        "    new_df.rename(columns={f's1_token_labs_{label_format}': 's1_token_labs',\n",
        "                            f's2_token_labs_{label_format}': 's2_token_labs',}, inplace=True)\n",
        "    return new_df\n",
        "\n",
        "def show_test_result(trainer, test_df):\n",
        "    test_result = trainer.predict(test['inputs'].values)\n",
        "\n",
        "    # Print default metrics collected during prediction\n",
        "    for item, value in test_result.metrics.items():\n",
        "        print(f\"{item}: {value}\")\n",
        "\n",
        "    predictions = torch.Tensor(test_result.predictions)\n",
        "    labels = torch.Tensor(test_result.label_ids)\n",
        "\n",
        "    # Compute class-wise metrics\n",
        "    #thresholds = [0.15, 0.5, 0.5, 0.5, 0.5, 0.19, 0.5, 0.5]\n",
        "    results = test_metrics((predictions, labels))\n",
        "    df = pd.DataFrame.from_dict(results)\n",
        "    #df.drop(columns = ['f1', 'roc_auc', 'hamming_loss'], inplace=True)\n",
        "    if num_labels == 4:\n",
        "        indices = [['1. Addition/Deletion', '2. Change of Order', '3. Substitution']]\n",
        "    else:\n",
        "        indices = [['1. Add/Del - Function Word', '2. Add/Del - Content Word', '3. Change of Order',\n",
        "             '4. Substitution - Synonym', '5. Substitution - Contextual Synonym', '6. Substitution - Morphological',\n",
        "             '7. Substitution - Spelling and Format', '8. Add/Del - Punctuation']]\n",
        "    df.index = indices\n",
        "    return df\n",
        "\n",
        "def show_multilabel_test_result(trainer, test_df):\n",
        "    test_result = trainer.predict(test['inputs'].values)\n",
        "\n",
        "    # Print default metrics collected during prediction\n",
        "    for item, value in test_result.metrics.items():\n",
        "        print(f\"{item}: {value}\")\n",
        "\n",
        "    predictions = torch.Tensor(test_result.predictions)\n",
        "    labels = torch.Tensor(test_result.label_ids)\n",
        "\n",
        "    # Compute class-wise metrics\n",
        "    #thresholds = [0.15, 0.5, 0.5, 0.5, 0.5, 0.19, 0.5, 0.5]\n",
        "    results = multilabel_test_metrics(predictions, labels)\n",
        "    df = pd.DataFrame.from_dict(results)\n",
        "    df.drop(columns = ['f1', 'roc_auc', 'hamming_loss'], inplace=True)\n",
        "    if num_labels == 3:\n",
        "        indices = [['1. Addition/Deletion', '2. Change of Order', '3. Substitution']]\n",
        "    else:\n",
        "        indices = [['1. Add/Del - Function Word', '2. Add/Del - Content Word', '3. Change of Order',\n",
        "             '4. Substitution - Synonym', '5. Substitution - Contextual Synonym', '6. Substitution - Morphological',\n",
        "             '7. Substitution - Spelling and Format', '8. Add/Del - Punctuation']]\n",
        "    df.index = indices\n",
        "    return df\n",
        "\n",
        "class MultiLabelTrainer(Trainer):\n",
        "    def __init__(self, *args, class_weights = None, **kwargs):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        if class_weights is not None:\n",
        "            class_weights = class_weights.to(self.args.device)\n",
        "            #logging.info(f\"Using multi-label classification with class weights\", class_weights)\n",
        "        self.loss_fct = BCEWithLogitsLoss(weight=class_weights)\n",
        "\n",
        "    def compute_loss(self, model, inputs, return_outputs=False):\n",
        "        \"\"\"\n",
        "        How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
        "        Subclass and override for custom behavior.\n",
        "        \"\"\"\n",
        "        labels  = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "        # this simultaneously accesses predictions for tokens that aren't CLS or PAD\n",
        "        # and flattens the logits or labels\n",
        "        flat_outputs = outputs.logits[labels!=-100]\n",
        "        flat_labels  = labels[labels!=-100]\n",
        "\n",
        "        try:\n",
        "            loss = self.loss_fct(flat_outputs, flat_labels.float())\n",
        "        except AttributeError:  # DataParallel\n",
        "            loss = self.loss_fct(flat_outputs, flat_labels.float())\n",
        "\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "def multilabel_metrics(predictions, labels, threshold=0.5):\n",
        "    # First, apply sigmoid on predictions\n",
        "    sigmoid = torch.nn.Sigmoid()\n",
        "    probs = sigmoid(torch.Tensor(predictions))\n",
        "    # Flatten probs and labels\n",
        "    # Originally of dims [batch_size, sequence_length, num_labels] to [batch_size * sequence_length, num_labels]\n",
        "    flat_probs = probs.view(-1, probs.shape[-1])\n",
        "    flat_labels = labels.reshape(-1, labels.shape[-1])\n",
        "\n",
        "    # Filter rows where all labels are -100\n",
        "    mask = ~(flat_labels == -100).all(axis=1)\n",
        "    filtered_probs = flat_probs[mask]\n",
        "    filtered_labels = flat_labels[mask]\n",
        "\n",
        "    # Generate predictions using threshold\n",
        "    y_pred = np.zeros(filtered_probs.shape)\n",
        "    y_pred[np.where(filtered_probs > threshold)] = 1\n",
        "\n",
        "    # Now we can compute metrics:\n",
        "    y_true = filtered_labels\n",
        "    #print(y_true)\n",
        "    #print(y_pred)\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
        "    roc_auc = roc_auc_score(y_true, y_pred, average = 'micro')\n",
        "    hamming = hamming_loss(y_true, y_pred)\n",
        "    metrics = {'f1': f1_micro_average,\n",
        "               'roc_auc': roc_auc,\n",
        "               'hamming loss': hamming}\n",
        "    return metrics\n",
        "\n",
        "def compute_multilabel_metrics(p: EvalPrediction):\n",
        "    preds = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "    result = multilabel_metrics(predictions=preds, labels=p.label_ids)\n",
        "    return result"
      ],
      "metadata": {
        "id": "uiq1FoiRFhio",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "174b3679-40ad-4d1f-9c56-7c93c62f8d6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle('thesis/datasets/etpc_reannotated.pkl')\n",
        "data = subset_labels(data, label_format)\n",
        "data.head()"
      ],
      "metadata": {
        "id": "1EhDYHKLgdgk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "2464302b-35b3-45d5-9418-80619d61f693"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-cae98db2de40>:259: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  new_df.rename(columns={f's1_token_labs_{label_format}': 's1_token_labs',\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           sentence1  \\\n",
              "0  Amrozi accused his brother, whom he called \"th...   \n",
              "2  They had published an advertisement on the Int...   \n",
              "4  The stock rose $2.11, or about 11 percent, to ...   \n",
              "5  Revenue in the first quarter of the year dropp...   \n",
              "7  The DVD-CCA then appealed to the state Supreme...   \n",
              "\n",
              "                                           sentence2  \\\n",
              "0  Referring to him as only \"the witness\", Amrozi...   \n",
              "2  On June 10, the ship's owners had published an...   \n",
              "4  PG&E Corp. shares jumped $1.63 or 8 percent to...   \n",
              "5  With the scandal hanging over Stewart's compan...   \n",
              "7  The DVD CCA appealed that decision to the U.S....   \n",
              "\n",
              "                                 sentence1_tokenized  \\\n",
              "0  [Amrozi, accused, his, brother, ,, whom, he, c...   \n",
              "2  [They, had, published, an, advertisement, on, ...   \n",
              "4  [The, stock, rose, $, 2.11, ,, or, about, 11, ...   \n",
              "5  [Revenue, in, the, first, quarter, of, the, ye...   \n",
              "7  [The, DVD-CCA, then, appealed, to, the, state,...   \n",
              "\n",
              "                                 sentence2_tokenized       collapsed_labels  \\\n",
              "0  [Referring, to, him, as, only, ``, the, witnes...           [0, 2, 3, 4]   \n",
              "2  [On, June, 10, ,, the, ship, 's, owners, had, ...        [0, 2, 3, 4, 5]   \n",
              "4  [PG, &, E, Corp., shares, jumped, $, 1.63, or,...  [0, 1, 2, 3, 4, 5, 8]   \n",
              "5  [With, the, scandal, hanging, over, Stewart, '...              [0, 1, 2]   \n",
              "7  [The, DVD, CCA, appealed, that, decision, to, ...        [0, 1, 2, 4, 7]   \n",
              "\n",
              "                                       s1_token_labs  \\\n",
              "0  [3, 3, 3, 3, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "2  [5, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 4, ...   \n",
              "4  [5, 5, 4, 0, 0, 8, 0, 2, 0, 0, 8, 0, 2, 3, 1, ...   \n",
              "5  [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...   \n",
              "7                     [0, 7, 2, 0, 0, 0, 4, 0, 0, 0]   \n",
              "\n",
              "                                       s2_token_labs  \n",
              "0  [4, 4, 4, 0, 2, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, ...  \n",
              "2  [3, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "4  [5, 5, 5, 5, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
              "5  [1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, ...  \n",
              "7               [0, 7, 7, 0, 1, 2, 0, 0, 4, 0, 0, 0]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6c4b120-4c34-4b38-9dfe-a011b25a77fe\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>collapsed_labels</th>\n",
              "      <th>s1_token_labs</th>\n",
              "      <th>s2_token_labs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
              "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
              "      <td>[Amrozi, accused, his, brother, ,, whom, he, c...</td>\n",
              "      <td>[Referring, to, him, as, only, ``, the, witnes...</td>\n",
              "      <td>[0, 2, 3, 4]</td>\n",
              "      <td>[3, 3, 3, 3, 0, 4, 0, 4, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[4, 4, 4, 0, 2, 0, 0, 0, 0, 0, 3, 3, 3, 3, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They had published an advertisement on the Int...</td>\n",
              "      <td>On June 10, the ship's owners had published an...</td>\n",
              "      <td>[They, had, published, an, advertisement, on, ...</td>\n",
              "      <td>[On, June, 10, ,, the, ship, 's, owners, had, ...</td>\n",
              "      <td>[0, 2, 3, 4, 5]</td>\n",
              "      <td>[5, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 0, 0, 0, 4, ...</td>\n",
              "      <td>[3, 3, 3, 3, 5, 5, 5, 5, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
              "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
              "      <td>[The, stock, rose, $, 2.11, ,, or, about, 11, ...</td>\n",
              "      <td>[PG, &amp;, E, Corp., shares, jumped, $, 1.63, or,...</td>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 8]</td>\n",
              "      <td>[5, 5, 4, 0, 0, 8, 0, 2, 0, 0, 8, 0, 2, 3, 1, ...</td>\n",
              "      <td>[5, 5, 5, 5, 5, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Revenue in the first quarter of the year dropp...</td>\n",
              "      <td>With the scandal hanging over Stewart's compan...</td>\n",
              "      <td>[Revenue, in, the, first, quarter, of, the, ye...</td>\n",
              "      <td>[With, the, scandal, hanging, over, Stewart, '...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "      <td>[1, 1, 2, 2, 2, 2, 2, 2, 2, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
              "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
              "      <td>[The, DVD-CCA, then, appealed, to, the, state,...</td>\n",
              "      <td>[The, DVD, CCA, appealed, that, decision, to, ...</td>\n",
              "      <td>[0, 1, 2, 4, 7]</td>\n",
              "      <td>[0, 7, 2, 0, 0, 0, 4, 0, 0, 0]</td>\n",
              "      <td>[0, 7, 7, 0, 1, 2, 0, 0, 4, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6c4b120-4c34-4b38-9dfe-a011b25a77fe')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6c4b120-4c34-4b38-9dfe-a011b25a77fe button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6c4b120-4c34-4b38-9dfe-a011b25a77fe');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-18c93b4f-9abc-413c-88e0-bb791bacedf6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-18c93b4f-9abc-413c-88e0-bb791bacedf6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-18c93b4f-9abc-413c-88e0-bb791bacedf6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3900,\n  \"fields\": [\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3899,\n        \"samples\": [\n          \"He said it was a mistake, and he reimbursed the party nearly $2,000.\",\n          \"Illinois State Police accident reconstruction experts were investigating the cause.\",\n          \"\\\"This deal makes sense for both companies,\\\" Brian Halla, National's chief executive, said in a statement.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3743,\n        \"samples\": [\n          \"Hidalgo County Judge Ramon Garcia says when he was growing up, he wasn't allowed to speak Spanish at school.\",\n          \"A judge already has ruled that double-jeopardy protections don't apply in the case.\",\n          \"The test, in four sections, includes algebra and geometry, along with some questions on probability and statistics.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1_tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2_tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"collapsed_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s1_token_labs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s2_token_labs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "kqtLGzqznnkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split"
      ],
      "metadata": {
        "id": "AZDrpicG-ref"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the collapsed labels here, since iterative stratification has trouble dealing with multi-dimensional arrays."
      ],
      "metadata": {
        "id": "ai0XyoOd01PJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indices selected for each set\n",
        "# It's easier to just use indices rather than having to deal with sentence pairs here\n",
        "indices = np.array(data.index.tolist())\n",
        "indices = np.expand_dims(indices, axis=1)\n",
        "indices.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d07a816b-b07b-48ae-a6c1-94f8d61eaf39",
        "id": "hCwmb9dg-pg_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3900, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels, converted\n",
        "labels = data['collapsed_labels'].values\n",
        "labels = [id_array_to_labels(each_list) for each_list in labels]\n",
        "data['labels'] = labels\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "N3aAErAjnZSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stratification"
      ],
      "metadata": {
        "id": "oVBOtnlCNX5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ITERATIVE STRATIFICATION\n",
        "np.random.seed(3)\n",
        "# 80/20 split into train and temp sets (temp set will be further split below)\n",
        "x_train, y_train, x_val_test, y_val_test = iterative_train_test_split(indices, labels, test_size=0.2)\n",
        "# 50/50 split temp set into validation and test sets\n",
        "x_val, y_val, x_test, y_test  = iterative_train_test_split(x_val_test, y_val_test, test_size=0.5)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31f31d27-e807-44d0-87e7-fab7698103ca",
        "id": "k5S-zwgn-phE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3087, 1)\n",
            "(414, 1)\n",
            "(399, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting indices in x matrices back to 1-d\n",
        "indices_train = np.squeeze(x_train)\n",
        "indices_test = np.squeeze(x_test)\n",
        "indices_val = np.squeeze(x_val)"
      ],
      "metadata": {
        "id": "IAudX1V_-phF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.loc[indices_train, :]\n",
        "test = data.loc[indices_test, :]\n",
        "val = data.loc[indices_val, :]"
      ],
      "metadata": {
        "id": "HOFC-iMo-phF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing"
      ],
      "metadata": {
        "id": "bas61Dh4mg3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "apply_tokenization(train, test, val)"
      ],
      "metadata": {
        "id": "5OZq3CvvFCRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "s5FqLYjal3WU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt9Myem0FvAQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "c722d5ae94134acf9e6fd5dc55a291c0",
            "1b22284565924259b99a155f59225a45",
            "e7eb5820d46d4d3196f0d9e0740b8615",
            "9d5832b236d1442fb550b7d6a6bf4d21",
            "68d40f3419f148c6a192e2f212c39954",
            "92cb9edf2b7d41f188e56c83d3ed76eb",
            "4ae9d623030a436aaeb06d1deee96c5d",
            "12f174afef2845e0a90a8991729e61d9",
            "9ac4b9a16ad74b84a7bc9617d7ca14b7",
            "8bfc1949187b4346952bff456fa890ca",
            "10e6be8be134487e9218907a1a665634"
          ]
        },
        "outputId": "ef01053f-94b4-4bf9-bb90-adbeb3091ca1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c722d5ae94134acf9e6fd5dc55a291c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "params = {'learning_rate': 0.00021437583926908025, 'num_train_epochs': 7, 'warmup_steps': 261, 'weight_decay': 0.03953905927366381, 'per_device_train_batch_size': 16}\n",
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"bert-paraop\",\n",
        "    eval_strategy = \"epoch\",\n",
        "    logging_steps = 10,\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=params['learning_rate'],\n",
        "    per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "    per_device_eval_batch_size=params['per_device_train_batch_size'],\n",
        "    num_train_epochs=params['num_train_epochs'],\n",
        "    warmup_steps=params['warmup_steps'],\n",
        "    weight_decay=params['weight_decay'],\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=2,\n",
        "    metric_for_best_model=metric_name\n",
        ")\n",
        "\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=None,\n",
        "    args=args,\n",
        "    train_dataset=train['inputs'].values,\n",
        "    eval_dataset=val['inputs'].values,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    model_init=model_init\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "IVVWvWvKjQja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "I_xrhbN3iKRu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = trainer.evaluate()\n",
        "for item, value in eval_result.items():\n",
        "    print(f\"{item}: {value}\")"
      ],
      "metadata": {
        "id": "o3iUk7UOFzRi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "GRAtLcULHwzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = trainer.predict(test['inputs'].values)\n",
        "\n",
        "# Print default metrics collected during prediction\n",
        "for item, value in test_result.metrics.items():\n",
        "    print(f\"{item}: {value}\")\n",
        "\n",
        "predictions = torch.Tensor(test_result.predictions)\n",
        "labels = torch.Tensor(test_result.label_ids)\n",
        "\n",
        "# Compute class-wise metrics\n",
        "#thresholds = [0.15, 0.5, 0.5, 0.5, 0.5, 0.19, 0.5, 0.5]\n",
        "results = test_metrics((predictions, labels))\n",
        "df = pd.DataFrame.from_dict(results)\n",
        "#df.drop(columns = ['f1', 'roc_auc', 'hamming_loss'], inplace=True)\n",
        "df.index = [['1. Add/Del - Function Word', '2. Add/Del - Content Word', '3. Change of Order',\n",
        "             '4. Substitution - Synonym', '5. Substitution - Contextual Synonym', '6. Substitution - Morphological',\n",
        "             '7. Substitution - Spelling and Format', '8. Add/Del - Punctuation']]\n",
        "df"
      ],
      "metadata": {
        "id": "6ZvS6i0n53Sb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Optional: Hyperparameter Search"
      ],
      "metadata": {
        "id": "CWRJjm6AStsW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining search space"
      ],
      "metadata": {
        "id": "wXrDQ3f8hQgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "search_space = {\n",
        "    \"learning_rate\": (1e-5, 3e-4),\n",
        "    \"num_train_epochs\": (4, 8),\n",
        "    \"warmup_steps\": (10, 300),\n",
        "    \"weight_decay\": (0.01, 0.05),\n",
        "    \"per_device_train_batch_size\": (8, 16, 32, 64, 128)\n",
        "}\n",
        "\n",
        "best_trials = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    hp_space=optuna_hp_space,\n",
        "    n_trials=15,\n",
        "    compute_objective=get_accuracy\n",
        ")"
      ],
      "metadata": {
        "id": "LRIiLcRBdy_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_trials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLYVAJvgEpyc",
        "outputId": "e38abbc0-11a0-4cf5-8ee1-46b2de0ad65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='1', objective=0.6022401184856059, hyperparameters={'learning_rate': 0.00021437583926908025, 'num_train_epochs': 7, 'warmup_steps': 261, 'weight_decay': 0.03953905927366381, 'per_device_train_batch_size': 16}, run_summary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ]
    }
  ]
}