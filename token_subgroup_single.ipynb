{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "LzbzljFengh_",
        "AZDrpicG-ref",
        "oVBOtnlCNX5X",
        "bas61Dh4mg3C",
        "CWRJjm6AStsW",
        "h06WTC4zLtbv"
      ],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cd750bce2ef5481bad8cda2f68316d3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05c5d7bce853471eb1bd95e686f420cd",
              "IPY_MODEL_66070237a2a44ee7a0d962e0df45625d",
              "IPY_MODEL_96f1561a84414944b244c9d803bebfab"
            ],
            "layout": "IPY_MODEL_94ddfd3300ee4b158c9494be99a176dd"
          }
        },
        "05c5d7bce853471eb1bd95e686f420cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58bb274b92444a96a0f98d8b96032b00",
            "placeholder": "​",
            "style": "IPY_MODEL_8ca27ad2dcbb446484d42b6f8bcd4850",
            "value": "model.safetensors: 100%"
          }
        },
        "66070237a2a44ee7a0d962e0df45625d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_315c56de2b4f4bc788eae8561a5c2b2c",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c1121488b49e4f4e862761502077325c",
            "value": 440449768
          }
        },
        "96f1561a84414944b244c9d803bebfab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a58bdf167df410eb033e0b446fc54d6",
            "placeholder": "​",
            "style": "IPY_MODEL_9b1f719e4e1d45169e15405eb633289f",
            "value": " 440M/440M [00:02&lt;00:00, 206MB/s]"
          }
        },
        "94ddfd3300ee4b158c9494be99a176dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bb274b92444a96a0f98d8b96032b00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ca27ad2dcbb446484d42b6f8bcd4850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "315c56de2b4f4bc788eae8561a5c2b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c1121488b49e4f4e862761502077325c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9a58bdf167df410eb033e0b446fc54d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b1f719e4e1d45169e15405eb633289f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Imports and Reading Files"
      ],
      "metadata": {
        "id": "LzbzljFengh_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets pandas transformers transformers[torch] scikit-multilearn optuna\n",
        "!git clone https://github.com/lucasadelino/thesis.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Lw0FxbQleFU",
        "outputId": "d039024f-7fc8-4e2c-bff1-9f85778cd73f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.20.0-py3-none-any.whl (547 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/547.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/547.8 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m542.7/547.8 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m547.8/547.8 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Collecting scikit-multilearn\n",
            "  Downloading scikit_multilearn-0.2.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.4/89.4 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optuna\n",
            "  Downloading optuna-3.6.1-py3-none-any.whl (380 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m380.1/380.1 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.15.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.25.2)\n",
            "Collecting pyarrow>=15.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.1.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests>=2.32.2 (from datasets)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.4)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.5.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers) (2.3.0+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers)\n",
            "  Downloading accelerate-0.32.1-py3-none-any.whl (314 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m314.1/314.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.8.2-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.31)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers) (5.9.5)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.6.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna) (3.0.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch->transformers)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers) (1.3.0)\n",
            "Installing collected packages: scikit-multilearn, xxhash, requests, pyarrow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, Mako, dill, colorlog, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, alembic, optuna, nvidia-cusolver-cu12, datasets, accelerate\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 16.1.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.32.3 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 accelerate-0.32.1 alembic-1.13.2 colorlog-6.8.2 datasets-2.20.0 dill-0.3.8 multiprocess-0.70.16 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 optuna-3.6.1 pyarrow-16.1.0 requests-2.32.3 scikit-multilearn-0.2.0 xxhash-3.4.1\n",
            "Cloning into 'thesis'...\n",
            "remote: Enumerating objects: 102, done.\u001b[K\n",
            "remote: Counting objects: 100% (102/102), done.\u001b[K\n",
            "remote: Compressing objects: 100% (76/76), done.\u001b[K\n",
            "remote: Total 102 (delta 36), reused 89 (delta 23), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (102/102), 9.23 MiB | 9.68 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "040vQsLhlAM_"
      },
      "outputs": [],
      "source": [
        "import ast\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from google.colab import files\n",
        "from transformers import AutoModelForSequenceClassification, BertTokenizer, BertForSequenceClassification, EvalPrediction, TrainingArguments, Trainer\n",
        "from sklearn.metrics import f1_score, roc_auc_score, hamming_loss\n",
        "from skmultilearn.model_selection import iterative_train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_pickle('thesis/datasets/etpc_reannotated.pkl')"
      ],
      "metadata": {
        "id": "1EhDYHKLgdgk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "ccYqXI4-mRX7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7e8cf89d-6ce5-4d56-c76d-1e1b46e93a25"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              sentence1  \\\n",
              "0     Amrozi accused his brother, whom he called \"th...   \n",
              "2     They had published an advertisement on the Int...   \n",
              "4     The stock rose $2.11, or about 11 percent, to ...   \n",
              "5     Revenue in the first quarter of the year dropp...   \n",
              "7     The DVD-CCA then appealed to the state Supreme...   \n",
              "...                                                 ...   \n",
              "5792  Gehring waived extradition Monday during a hea...   \n",
              "5793  \"I am advised that certain allegations of crim...   \n",
              "5795  The deal, approved by both companies' board of...   \n",
              "5799  Last week the power station’s US owners, AES C...   \n",
              "5800  Sobig.F spreads when unsuspecting computer use...   \n",
              "\n",
              "                                              sentence2  \\\n",
              "0     Referring to him as only \"the witness\", Amrozi...   \n",
              "2     On June 10, the ship's owners had published an...   \n",
              "4     PG&E Corp. shares jumped $1.63 or 8 percent to...   \n",
              "5     With the scandal hanging over Stewart's compan...   \n",
              "7     The DVD CCA appealed that decision to the U.S....   \n",
              "...                                                 ...   \n",
              "5792  Gehring waived extradition Monday during a hea...   \n",
              "5793  \"I am advised that certain allegations of crim...   \n",
              "5795  The acquisition has been approved by both comp...   \n",
              "5799  The news comes after Drax's American owner, AE...   \n",
              "5800  The virus spreads when unsuspecting computer u...   \n",
              "\n",
              "                                    sentence1_tokenized  \\\n",
              "0     [Amrozi, accused, his, brother, ,, whom, he, c...   \n",
              "2     [They, had, published, an, advertisement, on, ...   \n",
              "4     [The, stock, rose, $, 2.11, ,, or, about, 11, ...   \n",
              "5     [Revenue, in, the, first, quarter, of, the, ye...   \n",
              "7     [The, DVD-CCA, then, appealed, to, the, state,...   \n",
              "...                                                 ...   \n",
              "5792  [Gehring, waived, extradition, Monday, during,...   \n",
              "5793  [``, I, am, advised, that, certain, allegation...   \n",
              "5795  [The, deal, ,, approved, by, both, companies, ...   \n",
              "5799  [Last, week, the, power, station’s, US, owners...   \n",
              "5800  [Sobig.F, spreads, when, unsuspecting, compute...   \n",
              "\n",
              "                                    sentence2_tokenized  \\\n",
              "0     [Referring, to, him, as, only, ``, the, witnes...   \n",
              "2     [On, June, 10, ,, the, ship, 's, owners, had, ...   \n",
              "4     [PG, &, E, Corp., shares, jumped, $, 1.63, or,...   \n",
              "5     [With, the, scandal, hanging, over, Stewart, '...   \n",
              "7     [The, DVD, CCA, appealed, that, decision, to, ...   \n",
              "...                                                 ...   \n",
              "5792  [Gehring, waived, extradition, Monday, during,...   \n",
              "5793  [``, I, am, advised, that, certain, allegation...   \n",
              "5795  [The, acquisition, has, been, approved, by, bo...   \n",
              "5799  [The, news, comes, after, Drax, 's, American, ...   \n",
              "5800  [The, virus, spreads, when, unsuspecting, comp...   \n",
              "\n",
              "                                        sentence1_scope  \\\n",
              "0     [3_0, 3_0, 3_0, 3_0, 0_0, 4_0, 0_0, 4_1, 0_0, ...   \n",
              "2     [5_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 3_0, ...   \n",
              "4     [5_0, 5_0, 4_0, 0_0, 0_0, 8_0, 0_0, 2_0, 0_0, ...   \n",
              "5     [0_0, 1_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "7     [0_0, 7_0, 2_0, 0_0, 0_0, 0_0, 4_0, 0_0, 0_0, ...   \n",
              "...                                                 ...   \n",
              "5792  [0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "5793  [0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "5795  [0_0, 4_0, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, ...   \n",
              "5799  [3_0, 3_0, 0_0, 5_1, 5_1, 5_0, 6_0, 0_0, 0_0, ...   \n",
              "5800  [5_1, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "\n",
              "                                        sentence2_scope  \\\n",
              "0     [4_1, 4_0, 4_0, 0_0, 2_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "2     [3_0, 3_0, 3_0, 3_0, 5_0, 5_0, 5_0, 5_0, 0_0, ...   \n",
              "4     [5_0, 5_0, 5_0, 5_0, 5_0, 4_0, 0_0, 0_0, 0_0, ...   \n",
              "5     [1_3, 1_4, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, ...   \n",
              "7     [0_0, 7_0, 7_0, 0_0, 1_3, 2_1, 0_0, 0_0, 4_0, ...   \n",
              "...                                                 ...   \n",
              "5792  [0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 2_1, 2_1, ...   \n",
              "5793  [0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "5795  [0_0, 4_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "5799  [2_0, 2_0, 2_0, 2_0, 5_1, 0_0, 5_0, 6_0, 0_0, ...   \n",
              "5800  [5_1, 5_1, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...   \n",
              "\n",
              "           collapsed_labels  \\\n",
              "0              [0, 2, 3, 4]   \n",
              "2           [0, 2, 3, 4, 5]   \n",
              "4     [0, 1, 2, 3, 4, 5, 8]   \n",
              "5                 [0, 1, 2]   \n",
              "7           [0, 1, 2, 4, 7]   \n",
              "...                     ...   \n",
              "5792           [0, 2, 3, 8]   \n",
              "5793           [0, 2, 3, 8]   \n",
              "5795              [0, 2, 4]   \n",
              "5799     [0, 2, 3, 5, 6, 7]   \n",
              "5800        [0, 1, 2, 4, 5]   \n",
              "\n",
              "                                          s1_token_labs  \\\n",
              "0     [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
              "2     [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....   \n",
              "4     [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....   \n",
              "5     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1....   \n",
              "7     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
              "...                                                 ...   \n",
              "5792  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
              "5793  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
              "5795  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
              "5799  [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....   \n",
              "5800  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....   \n",
              "\n",
              "                                          s2_token_labs  \n",
              "0     [[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0....  \n",
              "2     [[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  \n",
              "4     [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....  \n",
              "5     [[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1....  \n",
              "7     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  \n",
              "...                                                 ...  \n",
              "5792  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  \n",
              "5793  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  \n",
              "5795  [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  \n",
              "5799  [[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....  \n",
              "5800  [[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....  \n",
              "\n",
              "[3900 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-214d7138-8fe3-49b1-a048-73acd7c58103\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence1</th>\n",
              "      <th>sentence2</th>\n",
              "      <th>sentence1_tokenized</th>\n",
              "      <th>sentence2_tokenized</th>\n",
              "      <th>sentence1_scope</th>\n",
              "      <th>sentence2_scope</th>\n",
              "      <th>collapsed_labels</th>\n",
              "      <th>s1_token_labs</th>\n",
              "      <th>s2_token_labs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Amrozi accused his brother, whom he called \"th...</td>\n",
              "      <td>Referring to him as only \"the witness\", Amrozi...</td>\n",
              "      <td>[Amrozi, accused, his, brother, ,, whom, he, c...</td>\n",
              "      <td>[Referring, to, him, as, only, ``, the, witnes...</td>\n",
              "      <td>[3_0, 3_0, 3_0, 3_0, 0_0, 4_0, 0_0, 4_1, 0_0, ...</td>\n",
              "      <td>[4_1, 4_0, 4_0, 0_0, 2_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0, 2, 3, 4]</td>\n",
              "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>They had published an advertisement on the Int...</td>\n",
              "      <td>On June 10, the ship's owners had published an...</td>\n",
              "      <td>[They, had, published, an, advertisement, on, ...</td>\n",
              "      <td>[On, June, 10, ,, the, ship, 's, owners, had, ...</td>\n",
              "      <td>[5_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 3_0, ...</td>\n",
              "      <td>[3_0, 3_0, 3_0, 3_0, 5_0, 5_0, 5_0, 5_0, 0_0, ...</td>\n",
              "      <td>[0, 2, 3, 4, 5]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The stock rose $2.11, or about 11 percent, to ...</td>\n",
              "      <td>PG&amp;E Corp. shares jumped $1.63 or 8 percent to...</td>\n",
              "      <td>[The, stock, rose, $, 2.11, ,, or, about, 11, ...</td>\n",
              "      <td>[PG, &amp;, E, Corp., shares, jumped, $, 1.63, or,...</td>\n",
              "      <td>[5_0, 5_0, 4_0, 0_0, 0_0, 8_0, 0_0, 2_0, 0_0, ...</td>\n",
              "      <td>[5_0, 5_0, 5_0, 5_0, 5_0, 4_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0, 1, 2, 3, 4, 5, 8]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Revenue in the first quarter of the year dropp...</td>\n",
              "      <td>With the scandal hanging over Stewart's compan...</td>\n",
              "      <td>[Revenue, in, the, first, quarter, of, the, ye...</td>\n",
              "      <td>[With, the, scandal, hanging, over, Stewart, '...</td>\n",
              "      <td>[0_0, 1_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[1_3, 1_4, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, ...</td>\n",
              "      <td>[0, 1, 2]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1....</td>\n",
              "      <td>[[1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [1....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>The DVD-CCA then appealed to the state Supreme...</td>\n",
              "      <td>The DVD CCA appealed that decision to the U.S....</td>\n",
              "      <td>[The, DVD-CCA, then, appealed, to, the, state,...</td>\n",
              "      <td>[The, DVD, CCA, appealed, that, decision, to, ...</td>\n",
              "      <td>[0_0, 7_0, 2_0, 0_0, 0_0, 0_0, 4_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0_0, 7_0, 7_0, 0_0, 1_3, 2_1, 0_0, 0_0, 4_0, ...</td>\n",
              "      <td>[0, 1, 2, 4, 7]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5792</th>\n",
              "      <td>Gehring waived extradition Monday during a hea...</td>\n",
              "      <td>Gehring waived extradition Monday during a hea...</td>\n",
              "      <td>[Gehring, waived, extradition, Monday, during,...</td>\n",
              "      <td>[Gehring, waived, extradition, Monday, during,...</td>\n",
              "      <td>[0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 2_1, 2_1, ...</td>\n",
              "      <td>[0, 2, 3, 8]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5793</th>\n",
              "      <td>\"I am advised that certain allegations of crim...</td>\n",
              "      <td>\"I am advised that certain allegations of crim...</td>\n",
              "      <td>[``, I, am, advised, that, certain, allegation...</td>\n",
              "      <td>[``, I, am, advised, that, certain, allegation...</td>\n",
              "      <td>[0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0, 2, 3, 8]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5795</th>\n",
              "      <td>The deal, approved by both companies' board of...</td>\n",
              "      <td>The acquisition has been approved by both comp...</td>\n",
              "      <td>[The, deal, ,, approved, by, both, companies, ...</td>\n",
              "      <td>[The, acquisition, has, been, approved, by, bo...</td>\n",
              "      <td>[0_0, 4_0, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, 2_0, ...</td>\n",
              "      <td>[0_0, 4_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0, 2, 4]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5799</th>\n",
              "      <td>Last week the power station’s US owners, AES C...</td>\n",
              "      <td>The news comes after Drax's American owner, AE...</td>\n",
              "      <td>[Last, week, the, power, station’s, US, owners...</td>\n",
              "      <td>[The, news, comes, after, Drax, 's, American, ...</td>\n",
              "      <td>[3_0, 3_0, 0_0, 5_1, 5_1, 5_0, 6_0, 0_0, 0_0, ...</td>\n",
              "      <td>[2_0, 2_0, 2_0, 2_0, 5_1, 0_0, 5_0, 6_0, 0_0, ...</td>\n",
              "      <td>[0, 2, 3, 5, 6, 7]</td>\n",
              "      <td>[[0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5800</th>\n",
              "      <td>Sobig.F spreads when unsuspecting computer use...</td>\n",
              "      <td>The virus spreads when unsuspecting computer u...</td>\n",
              "      <td>[Sobig.F, spreads, when, unsuspecting, compute...</td>\n",
              "      <td>[The, virus, spreads, when, unsuspecting, comp...</td>\n",
              "      <td>[5_1, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[5_1, 5_1, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, 0_0, ...</td>\n",
              "      <td>[0, 1, 2, 4, 5]</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "      <td>[[0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0], [0....</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3900 rows × 9 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-214d7138-8fe3-49b1-a048-73acd7c58103')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-214d7138-8fe3-49b1-a048-73acd7c58103 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-214d7138-8fe3-49b1-a048-73acd7c58103');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38d0500e-a035-492b-8459-114ee16481e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38d0500e-a035-492b-8459-114ee16481e0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38d0500e-a035-492b-8459-114ee16481e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_510fdb0a-573a-4672-b0ef-4c970d02bbc2\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_510fdb0a-573a-4672-b0ef-4c970d02bbc2 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 3900,\n  \"fields\": [\n    {\n      \"column\": \"sentence1\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3899,\n        \"samples\": [\n          \"He said it was a mistake, and he reimbursed the party nearly $2,000.\",\n          \"Illinois State Police accident reconstruction experts were investigating the cause.\",\n          \"\\\"This deal makes sense for both companies,\\\" Brian Halla, National's chief executive, said in a statement.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3743,\n        \"samples\": [\n          \"Hidalgo County Judge Ramon Garcia says when he was growing up, he wasn't allowed to speak Spanish at school.\",\n          \"A judge already has ruled that double-jeopardy protections don't apply in the case.\",\n          \"The test, in four sections, includes algebra and geometry, along with some questions on probability and statistics.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1_tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2_tokenized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence1_scope\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentence2_scope\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"collapsed_labels\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s1_token_labs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"s2_token_labs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['sentence1_tokenized'] = data['sentence1_tokenized'].apply(lambda x: list(x))\n",
        "data['sentence2_tokenized'] = data['sentence2_tokenized'].apply(lambda x: list(x))"
      ],
      "metadata": {
        "id": "fw3G7fq8ett8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['collapsed_labels'] = data['collapsed_labels'].apply(lambda x: [int(i) for i in x])"
      ],
      "metadata": {
        "id": "hjZbmxiSn0od"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "kqtLGzqznnkl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train/Test Split"
      ],
      "metadata": {
        "id": "AZDrpicG-ref"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We'll use the collapsed labels here, since iterative stratification has trouble dealing with multi-dimensional arrays."
      ],
      "metadata": {
        "id": "ai0XyoOd01PJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Indices selected for each set\n",
        "# It's easier to just use indices rather than having to deal with sentence pairs here\n",
        "indices = np.array(data.index.tolist())\n",
        "indices = np.expand_dims(indices, axis=1)\n",
        "indices.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f322f7d8-64b2-4ff7-fad3-6e2d58fb3648",
        "id": "hCwmb9dg-pg_"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3900, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def id_array_to_labels(id_array):\n",
        "    \"\"\"Converts an array of indices to a bit array\n",
        "    e.g. the array [1, 3] is converted to [0, 1, 0, 1]\"\"\"\n",
        "    labels = np.zeros(9)\n",
        "    labels[id_array] = 1\n",
        "    return labels.astype(float)\n",
        "\n",
        "# Example of the output\n",
        "example = [0, 2, 3, 4, 5]\n",
        "print(example)\n",
        "print(id_array_to_labels(example))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "862161da-ffdc-4d7c-d3c9-339fb0ec829d",
        "id": "-wxoctIx-phC"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 2, 3, 4, 5]\n",
            "[1. 0. 1. 1. 1. 1. 0. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Labels, converted\n",
        "labels = data['collapsed_labels'].values\n",
        "labels = [id_array_to_labels(each_list) for each_list in labels]\n",
        "data['labels'] = labels\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Making sure it worked\n",
        "data['s1_token_labs'][0]"
      ],
      "metadata": {
        "id": "N3aAErAjnZSm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7d7755d-f664-47e0-fe53-78b1dc873531"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 1., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating descriptive statistics"
      ],
      "metadata": {
        "id": "_pl9_xgUttac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's vertically stack all of the the labels, from both sentence 1 and sentence 2, into one big array"
      ],
      "metadata": {
        "id": "M43wQf_DOOrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_stack = np.concatenate((np.vstack(data['s1_token_labs'].values), np.vstack(data['s2_token_labs'].values)), axis=0)\n",
        "label_stack.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaR48QCoEG2Q",
        "outputId": "4cabac76-e5f1-4dc1-cbd5-caa7398a87c9"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(175199, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's see how many rows (i.e. how many tokens) have more than one label"
      ],
      "metadata": {
        "id": "q0Lgss_CPAh7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "row_sums = np.sum(label_stack, axis=1)\n",
        "label_stack[row_sums == 2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9HycXulIFhD",
        "outputId": "6203765f-8313-47d7-92f5-1199967bfd35"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1743, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XKJJKE4EPyZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1415/175199"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kUlvbGzyXi9_",
        "outputId": "880c94a5-110c-41d3-86b9-558b79c6f822"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.008076530117181034"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proportion of tokens with 2:\n",
        "0.009948686921729006\n",
        "\n",
        "Proportion of tokens with 3:\n",
        "9.132472217307176e-05"
      ],
      "metadata": {
        "id": "rHwGRKeRIPXW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's get rid of rows where all labels are zero"
      ],
      "metadata": {
        "id": "-z45hRJpP35d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_label_stack = label_stack[label_stack.any(axis=1)]\n",
        "trimmed_label_stack.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjbqTjodyQ7E",
        "outputId": "a3d065bb-0fd1-4a9c-bd0f-d5a4ea4593a0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49167, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's again calculate how many rows have more than one label"
      ],
      "metadata": {
        "id": "_-Br_pFZQMg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trimmed_row_sums = np.sum(trimmed_label_stack, axis=1)\n",
        "trimmed_label_stack[trimmed_row_sums == 2].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ThogUo3Lyh9u",
        "outputId": "7c3dad8f-6f8d-40f9-8d07-a364ee2a22f2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1743, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sent1multi = data['s1_token_labs'].apply(lambda x: np.max(np.sum(x, axis=1)) > 1.0)\n",
        "sent2multi = data['s2_token_labs'].apply(lambda x: np.max(np.sum(x, axis=1)) > 1.0)"
      ],
      "metadata": {
        "id": "ZJa23qwuJRcI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proportion of sentences with one or more:"
      ],
      "metadata": {
        "id": "nOIF-Z-AKGcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent1_prop = sent1multi.value_counts()[1] / sent1multi.value_counts()[0]\n",
        "sent2_prop = sent2multi.value_counts()[1] / sent2multi.value_counts()[0]\n",
        "\n",
        "print(sent1_prop)\n",
        "print(sent2_prop)\n",
        "print()\n",
        "\n",
        "total_prop  = sent1_prop + sent2_prop\n",
        "print(total_prop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UFqks4vTJwS_",
        "outputId": "b114a4da-ba40-4188-e0fd-66d81b94934e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.13537117903930132\n",
            "0.13471050334594123\n",
            "\n",
            "0.27008168238524255\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Proportion of sentences with two or more:"
      ],
      "metadata": {
        "id": "599K_YenRGOf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent1multi = data['s1_token_labs'].apply(lambda x: np.max(np.sum(x, axis=1)) > 2.0)\n",
        "sent2multi = data['s2_token_labs'].apply(lambda x: np.max(np.sum(x, axis=1)) > 2.0)"
      ],
      "metadata": {
        "id": "0f1Ojclczb6S"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent1_prop = sent1multi.value_counts()[1] / sent1multi.value_counts()[0]\n",
        "sent2_prop = sent2multi.value_counts()[1] / sent2multi.value_counts()[0]\n",
        "\n",
        "print(sent1_prop)\n",
        "print(sent2_prop)\n",
        "print()\n",
        "\n",
        "total_prop  = sent1_prop + sent2_prop\n",
        "print(total_prop)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSFDwFGBziPt",
        "outputId": "960c1dcb-448c-4f51-cb2b-5ff41bd0db2e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0020554984583761563\n",
            "0.0017980991523246853\n",
            "\n",
            "0.0038535976107008417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "lZDM9pAl1pIe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Figuring out label distributions"
      ],
      "metadata": {
        "id": "NDoiZCK8mnnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collapsing"
      ],
      "metadata": {
        "id": "-N01-AEDKRmY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's first determine how to resolve label conflicts:"
      ],
      "metadata": {
        "id": "5xHB76v_VlYF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "map = [\n",
        "    (np.array([1., 0., 0., 0., 1., 0., 0., 0.]), 4),\n",
        "    (np.array([0., 1., 0., 0., 0., 1., 0., 0.]), 1),\n",
        "    (np.array([0., 1., 0., 1., 0., 0., 0., 0.]), 3),\n",
        "    (np.array([0., 1., 0., 0., 1., 0., 0., 0.]), 4),\n",
        "    (np.array([0., 1., 0., 0., 0., 0., 0., 1.]), 7),\n",
        "    (np.array([0., 0., 0., 1., 1., 0., 0., 0.]), 3),\n",
        "    (np.array([0., 0., 0., 1., 0., 1., 0., 0.]), 3),\n",
        "    (np.array([0., 0., 0., 1., 0., 0., 1., 0.]), 6),\n",
        "    (np.array([0., 0., 0., 0., 1., 1., 0., 0.]), 4),\n",
        "    (np.array([0., 0., 0., 0., 1., 0., 1., 0.]), 6),\n",
        "    (np.array([0., 0., 0., 0., 1., 0., 0., 1.]), 7),\n",
        "    (np.array([0., 0., 0., 0., 0., 1., 1., 0.]), 6),\n",
        "    (np.array([0., 0., 0., 1., 0., 1., 0., 1.]), 5),\n",
        "    (np.array([0., 0., 0., 0., 0., 1., 0., 1.]), 7),\n",
        "    (np.array([0., 1., 0., 0., 0., 0., 1., 0.]), 6)\n",
        "]"
      ],
      "metadata": {
        "id": "sOBbGQBM1D_f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_multi_to_single(label_array):\n",
        "    # First, check if there's more than one value AND there's a change of order\n",
        "    # Change of orders will only occur if there's no other substitutions\n",
        "    if np.sum(label_array) == 0:\n",
        "        return 0\n",
        "    if np.sum(label_array) > 1 and label_array[2] == 1:\n",
        "        label_array[2] = 0\n",
        "    # Return index if there's only one element\n",
        "    if np.sum(label_array) == 1:\n",
        "        return np.argmax(label_array) + 1\n",
        "    # Lookup the map if there's more than one element\n",
        "    else:\n",
        "        for array, value in map:\n",
        "            if np.array_equal(array, label_array):\n",
        "                return value + 1\n",
        "\n",
        "# Example usage:\n",
        "example = np.array([0., 1., 1., 0., 1., 0., 0., 0.])\n",
        "convert_multi_to_single(example)"
      ],
      "metadata": {
        "id": "Ruvz8YPV7_Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, to actually perform the conversion:"
      ],
      "metadata": {
        "id": "hd7B3lbDVqBe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['s1_token_labs'] = data['s1_token_labs'].apply(lambda x: [convert_multi_to_single(row) for row in x])\n",
        "data['s2_token_labs'] = data['s2_token_labs'].apply(lambda x: [convert_multi_to_single(row) for row in x])"
      ],
      "metadata": {
        "id": "D4dFHNZyNkGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stratification"
      ],
      "metadata": {
        "id": "oVBOtnlCNX5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ITERATIVE STRATIFICATION\n",
        "np.random.seed(3)\n",
        "# 80/20 split into train and temp sets (temp set will be further split below)\n",
        "x_train, y_train, x_val_test, y_val_test = iterative_train_test_split(indices, labels, test_size=0.2)\n",
        "# 50/50 split temp set into validation and test sets\n",
        "x_val, y_val, x_test, y_test  = iterative_train_test_split(x_val_test, y_val_test, test_size=0.5)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_val.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6179180c-b8c5-4047-b4f8-f782d92de31c",
        "id": "k5S-zwgn-phE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3087, 1)\n",
            "(414, 1)\n",
            "(399, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting indices in x matrices back to 1-d\n",
        "indices_train = np.squeeze(x_train)\n",
        "indices_test = np.squeeze(x_test)\n",
        "indices_val = np.squeeze(x_val)"
      ],
      "metadata": {
        "id": "IAudX1V_-phF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = data.loc[indices_train, :]\n",
        "test = data.loc[indices_test, :]\n",
        "val = data.loc[indices_val, :]"
      ],
      "metadata": {
        "id": "HOFC-iMo-phF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing"
      ],
      "metadata": {
        "id": "bas61Dh4mg3C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model_type = 'bert-large-uncased'\n",
        "model_type = 'bert-base-uncased'"
      ],
      "metadata": {
        "id": "bhoAJE2zDWg5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_type)\n",
        "\n",
        "def tokenize_and_align_labels(example):\n",
        "    # Tokenize the sentence pair\n",
        "    tokenized_inputs = tokenizer(example[\"sentence1_tokenized\"], example[\"sentence2_tokenized\"],padding='max_length', max_length=90,\n",
        "                                 truncation=True, is_split_into_words=True)\n",
        "\n",
        "    label_array_1 = example['s1_token_labs']  # Label array for the first sentence\n",
        "    label_array_2 = example['s2_token_labs']  # Label array for the second sentence\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=0)\n",
        "\n",
        "    label_ids = []\n",
        "    sentence_switch = False  # Flag to indicate when to switch from the first to the second sentence's labels\n",
        "    previous_word_id = None\n",
        "\n",
        "    for index, word_id in enumerate(word_ids):\n",
        "        if word_id is None and not sentence_switch:\n",
        "            # First [CLS] or [SEP] token encountered\n",
        "            label_ids.append(-100)\n",
        "            if index > 0:\n",
        "                # First [SEP] token encountered\n",
        "                sentence_switch = True  # Switch to the second sentence's labels\n",
        "        elif word_id is None:\n",
        "            # Second [SEP] token or [CLS] token at the end\n",
        "            label_ids.append(-100)\n",
        "        else:\n",
        "            # Normal token, choose appropriate label array\n",
        "            current_label_array = label_array_2 if sentence_switch else label_array_1\n",
        "            label_ids.append(current_label_array[word_id])\n",
        "\n",
        "        previous_word_id = word_id\n",
        "\n",
        "    tokenized_inputs[\"labels\"] = label_ids\n",
        "\n",
        "    return tokenized_inputs"
      ],
      "metadata": {
        "id": "AKFg7WJeVg5k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b4084da-e214-4029-c897-16d4f9198ccf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYdFYt8EsYb5"
      },
      "outputs": [],
      "source": [
        "# Tokenize sentences and save as new column in dfs\n",
        "train['tokenized_sentences'] = train.apply(tokenize_and_align_labels, axis=1)\n",
        "test['tokenized_sentences'] = test.apply(tokenize_and_align_labels, axis=1)\n",
        "val['tokenized_sentences'] = val.apply(tokenize_and_align_labels, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert tokenized sentences to tensors. Those will be the inputs to our (PyTorch) model\n",
        "train['inputs'] = train['tokenized_sentences'].apply(lambda x: x.convert_to_tensors('pt'))\n",
        "test['inputs'] = test['tokenized_sentences'].apply(lambda x: x.convert_to_tensors('pt'))\n",
        "val['inputs'] = val['tokenized_sentences'].apply(lambda x: x.convert_to_tensors('pt'))"
      ],
      "metadata": {
        "id": "8M9tXGExAyzQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training"
      ],
      "metadata": {
        "id": "s5FqLYjal3WU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PObSuxhJBLo"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, precision_recall_fscore_support, accuracy_score, f1_score\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    y_pred = [\n",
        "        p for prediction, label in zip(predictions, labels)\n",
        "        for p, l in zip(prediction, label) if l != -100\n",
        "    ]\n",
        "    y_true = [\n",
        "        l for label in labels\n",
        "        for l in label if l != -100\n",
        "    ]\n",
        "\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
        "    accuracy = f1_score(y_true, y_pred, average='micro', labels=[1,2,3,4,5,6,7,8])\n",
        "    inflated_accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
        "    recall = recall_score(y_true=y_true, y_pred=y_pred, average='weighted')\n",
        "    results = {'f1': f1_micro_average,\n",
        "               'accuracy': accuracy,\n",
        "               '0accuracy': inflated_accuracy,\n",
        "               'precision': precision,\n",
        "               'recall': recall}\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt9Myem0FvAQ"
      },
      "outputs": [],
      "source": [
        "params = {'learning_rate': 0.00021437583926908025, 'num_train_epochs': 7, 'warmup_steps': 261, 'weight_decay': 0.03953905927366381, 'per_device_train_batch_size': 16}\n",
        "\n",
        "metric_name = \"accuracy\"\n",
        "\n",
        "args = TrainingArguments(\n",
        "    f\"bert-paraop\",\n",
        "    evaluation_strategy = \"epoch\",\n",
        "    logging_steps = 10,\n",
        "    save_strategy = \"epoch\",\n",
        "    learning_rate=params['learning_rate'],\n",
        "    per_device_train_batch_size=params['per_device_train_batch_size'],\n",
        "    per_device_eval_batch_size=params['per_device_train_batch_size'],\n",
        "    num_train_epochs=params['num_train_epochs'],\n",
        "    warmup_steps=params['warmup_steps'],\n",
        "    weight_decay=params['weight_decay'],\n",
        "    #optim = 'adamw_torch',\n",
        "    load_best_model_at_end=True,\n",
        "    save_total_limit=2,\n",
        "    metric_for_best_model=metric_name\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForTokenClassification\n",
        "\n",
        "def model_init():\n",
        "    return BertForTokenClassification.from_pretrained(model_type, num_labels=9)"
      ],
      "metadata": {
        "id": "Sw4B38srO6GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DataCollatorForTokenClassification\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "Bt6-2h15iJ12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=None,\n",
        "    args=args,\n",
        "    train_dataset=train['inputs'].values,\n",
        "    eval_dataset=val['inputs'].values,\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        "    model_init=model_init\n",
        ")"
      ],
      "metadata": {
        "id": "OHdl9RZ5ixVy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "cd750bce2ef5481bad8cda2f68316d3a",
            "05c5d7bce853471eb1bd95e686f420cd",
            "66070237a2a44ee7a0d962e0df45625d",
            "96f1561a84414944b244c9d803bebfab",
            "94ddfd3300ee4b158c9494be99a176dd",
            "58bb274b92444a96a0f98d8b96032b00",
            "8ca27ad2dcbb446484d42b6f8bcd4850",
            "315c56de2b4f4bc788eae8561a5c2b2c",
            "c1121488b49e4f4e862761502077325c",
            "9a58bdf167df410eb033e0b446fc54d6",
            "9b1f719e4e1d45169e15405eb633289f"
          ]
        },
        "outputId": "365824fc-0d7b-4ec5-aa93-e00a7f164ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd750bce2ef5481bad8cda2f68316d3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter Search"
      ],
      "metadata": {
        "id": "CWRJjm6AStsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def optuna_hp_space(trial):\n",
        "    return {\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 1e-5, 3e-4, log=True),\n",
        "        \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 4, 8),\n",
        "        \"warmup_steps\": trial.suggest_int(\"warmup_steps\", 10, 300),\n",
        "        \"weight_decay\": trial.suggest_float(\"weight_decay\", 0.01, 0.05, log=True),\n",
        "        \"per_device_train_batch_size\": trial.suggest_categorical(\"per_device_train_batch_size\", [8, 16, 32, 64, 128]),\n",
        "    }"
      ],
      "metadata": {
        "id": "wf2VB5jhHZ84"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_accuracy(input):\n",
        "    return input['eval_accuracy']"
      ],
      "metadata": {
        "id": "eHRTbXEsQOyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_trials = trainer.hyperparameter_search(\n",
        "    direction=\"maximize\",\n",
        "    backend=\"optuna\",\n",
        "    hp_space=optuna_hp_space,\n",
        "    n_trials=15,\n",
        "    compute_objective=get_accuracy\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X6Fys4SgIBoO",
        "outputId": "2bc9c960-6842-406f-c38d-05606e44aab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 20:42:33,065] A new study created in memory with name: no-name-adfa9f03-ba3c-47b5-907d-8ae3b7216b21\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='582' max='582' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [582/582 02:38, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.872800</td>\n",
              "      <td>0.745739</td>\n",
              "      <td>0.703098</td>\n",
              "      <td>0.284049</td>\n",
              "      <td>0.767236</td>\n",
              "      <td>0.685518</td>\n",
              "      <td>0.767236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.722900</td>\n",
              "      <td>0.664146</td>\n",
              "      <td>0.755487</td>\n",
              "      <td>0.400708</td>\n",
              "      <td>0.789251</td>\n",
              "      <td>0.731954</td>\n",
              "      <td>0.789251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.685900</td>\n",
              "      <td>0.616349</td>\n",
              "      <td>0.777008</td>\n",
              "      <td>0.466127</td>\n",
              "      <td>0.799199</td>\n",
              "      <td>0.768874</td>\n",
              "      <td>0.799199</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.644100</td>\n",
              "      <td>0.599474</td>\n",
              "      <td>0.792944</td>\n",
              "      <td>0.498727</td>\n",
              "      <td>0.804449</td>\n",
              "      <td>0.788886</td>\n",
              "      <td>0.804449</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.572800</td>\n",
              "      <td>0.592769</td>\n",
              "      <td>0.792471</td>\n",
              "      <td>0.495341</td>\n",
              "      <td>0.808272</td>\n",
              "      <td>0.786913</td>\n",
              "      <td>0.808272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.544500</td>\n",
              "      <td>0.586798</td>\n",
              "      <td>0.796100</td>\n",
              "      <td>0.507876</td>\n",
              "      <td>0.809745</td>\n",
              "      <td>0.791040</td>\n",
              "      <td>0.809745</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 20:45:12,745] Trial 0 finished with value: 0.50787552823665 and parameters: {'learning_rate': 1.3883099240911918e-05, 'num_train_epochs': 6, 'warmup_steps': 38, 'weight_decay': 0.024425404939089877, 'per_device_train_batch_size': 32}. Best is trial 0 with value: 0.50787552823665.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1351' max='1351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1351/1351 03:39, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.650900</td>\n",
              "      <td>0.600932</td>\n",
              "      <td>0.780548</td>\n",
              "      <td>0.465978</td>\n",
              "      <td>0.804081</td>\n",
              "      <td>0.774927</td>\n",
              "      <td>0.804081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.588600</td>\n",
              "      <td>0.529387</td>\n",
              "      <td>0.805123</td>\n",
              "      <td>0.533891</td>\n",
              "      <td>0.824851</td>\n",
              "      <td>0.812999</td>\n",
              "      <td>0.824851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.451800</td>\n",
              "      <td>0.545477</td>\n",
              "      <td>0.823723</td>\n",
              "      <td>0.579067</td>\n",
              "      <td>0.830148</td>\n",
              "      <td>0.823815</td>\n",
              "      <td>0.830148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.274000</td>\n",
              "      <td>0.612707</td>\n",
              "      <td>0.824042</td>\n",
              "      <td>0.572624</td>\n",
              "      <td>0.827983</td>\n",
              "      <td>0.822419</td>\n",
              "      <td>0.827983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.182300</td>\n",
              "      <td>0.654275</td>\n",
              "      <td>0.828788</td>\n",
              "      <td>0.590069</td>\n",
              "      <td>0.836365</td>\n",
              "      <td>0.825945</td>\n",
              "      <td>0.836365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.134300</td>\n",
              "      <td>0.702531</td>\n",
              "      <td>0.826415</td>\n",
              "      <td>0.587676</td>\n",
              "      <td>0.831391</td>\n",
              "      <td>0.824985</td>\n",
              "      <td>0.831391</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.073600</td>\n",
              "      <td>0.757106</td>\n",
              "      <td>0.833758</td>\n",
              "      <td>0.602240</td>\n",
              "      <td>0.838714</td>\n",
              "      <td>0.830620</td>\n",
              "      <td>0.838714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 20:48:52,766] Trial 1 finished with value: 0.6022401184856059 and parameters: {'learning_rate': 0.00021437583926908025, 'num_train_epochs': 7, 'warmup_steps': 261, 'weight_decay': 0.03953905927366381, 'per_device_train_batch_size': 16}. Best is trial 1 with value: 0.6022401184856059.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='294' max='294' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [294/294 02:26, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.993300</td>\n",
              "      <td>0.727208</td>\n",
              "      <td>0.725283</td>\n",
              "      <td>0.315256</td>\n",
              "      <td>0.773730</td>\n",
              "      <td>0.693909</td>\n",
              "      <td>0.773730</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.689700</td>\n",
              "      <td>0.608229</td>\n",
              "      <td>0.775716</td>\n",
              "      <td>0.446616</td>\n",
              "      <td>0.800488</td>\n",
              "      <td>0.788228</td>\n",
              "      <td>0.800488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.565200</td>\n",
              "      <td>0.568194</td>\n",
              "      <td>0.808987</td>\n",
              "      <td>0.543876</td>\n",
              "      <td>0.820845</td>\n",
              "      <td>0.805541</td>\n",
              "      <td>0.820845</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.430400</td>\n",
              "      <td>0.577132</td>\n",
              "      <td>0.805064</td>\n",
              "      <td>0.523883</td>\n",
              "      <td>0.806752</td>\n",
              "      <td>0.809969</td>\n",
              "      <td>0.806752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.284500</td>\n",
              "      <td>0.615988</td>\n",
              "      <td>0.813665</td>\n",
              "      <td>0.549222</td>\n",
              "      <td>0.824437</td>\n",
              "      <td>0.810209</td>\n",
              "      <td>0.824437</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.161600</td>\n",
              "      <td>0.641826</td>\n",
              "      <td>0.826676</td>\n",
              "      <td>0.591528</td>\n",
              "      <td>0.834155</td>\n",
              "      <td>0.822322</td>\n",
              "      <td>0.834155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 20:51:20,816] Trial 2 finished with value: 0.5915281299896684 and parameters: {'learning_rate': 0.0002467777902742531, 'num_train_epochs': 6, 'warmup_steps': 196, 'weight_decay': 0.012887151692844382, 'per_device_train_batch_size': 64}. Best is trial 1 with value: 0.6022401184856059.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [245/245 02:04, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.232000</td>\n",
              "      <td>0.972041</td>\n",
              "      <td>0.628894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.739603</td>\n",
              "      <td>0.547013</td>\n",
              "      <td>0.739603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.839100</td>\n",
              "      <td>0.698173</td>\n",
              "      <td>0.744944</td>\n",
              "      <td>0.362054</td>\n",
              "      <td>0.782158</td>\n",
              "      <td>0.717853</td>\n",
              "      <td>0.782158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.699600</td>\n",
              "      <td>0.595173</td>\n",
              "      <td>0.791362</td>\n",
              "      <td>0.499804</td>\n",
              "      <td>0.809331</td>\n",
              "      <td>0.786542</td>\n",
              "      <td>0.809331</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.550700</td>\n",
              "      <td>0.551838</td>\n",
              "      <td>0.810491</td>\n",
              "      <td>0.549066</td>\n",
              "      <td>0.816193</td>\n",
              "      <td>0.809042</td>\n",
              "      <td>0.816193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.475900</td>\n",
              "      <td>0.556591</td>\n",
              "      <td>0.808949</td>\n",
              "      <td>0.540500</td>\n",
              "      <td>0.813522</td>\n",
              "      <td>0.810338</td>\n",
              "      <td>0.813522</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 20:53:26,987] Trial 3 finished with value: 0.5405004633920296 and parameters: {'learning_rate': 7.383840384367708e-05, 'num_train_epochs': 5, 'warmup_steps': 242, 'weight_decay': 0.021487515580884516, 'per_device_train_batch_size': 64}. Best is trial 1 with value: 0.6022401184856059.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2316' max='2316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2316/2316 04:02, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.657100</td>\n",
              "      <td>0.578635</td>\n",
              "      <td>0.786916</td>\n",
              "      <td>0.484579</td>\n",
              "      <td>0.810574</td>\n",
              "      <td>0.786530</td>\n",
              "      <td>0.810574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.525900</td>\n",
              "      <td>0.524742</td>\n",
              "      <td>0.810826</td>\n",
              "      <td>0.551091</td>\n",
              "      <td>0.828167</td>\n",
              "      <td>0.825329</td>\n",
              "      <td>0.828167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.320900</td>\n",
              "      <td>0.510515</td>\n",
              "      <td>0.831927</td>\n",
              "      <td>0.602327</td>\n",
              "      <td>0.831898</td>\n",
              "      <td>0.833127</td>\n",
              "      <td>0.831898</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.251800</td>\n",
              "      <td>0.591868</td>\n",
              "      <td>0.832847</td>\n",
              "      <td>0.601727</td>\n",
              "      <td>0.834247</td>\n",
              "      <td>0.832741</td>\n",
              "      <td>0.834247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.102000</td>\n",
              "      <td>0.663671</td>\n",
              "      <td>0.831460</td>\n",
              "      <td>0.597887</td>\n",
              "      <td>0.837056</td>\n",
              "      <td>0.828201</td>\n",
              "      <td>0.837056</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.084400</td>\n",
              "      <td>0.710073</td>\n",
              "      <td>0.832306</td>\n",
              "      <td>0.601807</td>\n",
              "      <td>0.837931</td>\n",
              "      <td>0.828970</td>\n",
              "      <td>0.837931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 20:57:30,167] Trial 4 finished with value: 0.6018074511250462 and parameters: {'learning_rate': 7.616236619402955e-05, 'num_train_epochs': 6, 'warmup_steps': 254, 'weight_decay': 0.013188467848638568, 'per_device_train_batch_size': 8}. Best is trial 1 with value: 0.6022401184856059.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='97' max='485' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 97/485 00:24 < 01:38, 3.95 it/s, Epoch 1/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.913500</td>\n",
              "      <td>0.761012</td>\n",
              "      <td>0.696410</td>\n",
              "      <td>0.269547</td>\n",
              "      <td>0.764980</td>\n",
              "      <td>0.665965</td>\n",
              "      <td>0.764980</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 20:57:55,263] Trial 5 pruned. \n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='679' max='679' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [679/679 03:04, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.811200</td>\n",
              "      <td>0.701098</td>\n",
              "      <td>0.745899</td>\n",
              "      <td>0.381700</td>\n",
              "      <td>0.781559</td>\n",
              "      <td>0.720351</td>\n",
              "      <td>0.781559</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.630300</td>\n",
              "      <td>0.566438</td>\n",
              "      <td>0.795345</td>\n",
              "      <td>0.520388</td>\n",
              "      <td>0.816700</td>\n",
              "      <td>0.790876</td>\n",
              "      <td>0.816700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.523800</td>\n",
              "      <td>0.533674</td>\n",
              "      <td>0.816523</td>\n",
              "      <td>0.561957</td>\n",
              "      <td>0.826463</td>\n",
              "      <td>0.818008</td>\n",
              "      <td>0.826463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.400100</td>\n",
              "      <td>0.556071</td>\n",
              "      <td>0.821601</td>\n",
              "      <td>0.572517</td>\n",
              "      <td>0.826648</td>\n",
              "      <td>0.820347</td>\n",
              "      <td>0.826648</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.256400</td>\n",
              "      <td>0.603061</td>\n",
              "      <td>0.821966</td>\n",
              "      <td>0.576456</td>\n",
              "      <td>0.831207</td>\n",
              "      <td>0.817707</td>\n",
              "      <td>0.831207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.176200</td>\n",
              "      <td>0.633648</td>\n",
              "      <td>0.828337</td>\n",
              "      <td>0.594320</td>\n",
              "      <td>0.834016</td>\n",
              "      <td>0.825018</td>\n",
              "      <td>0.834016</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.125500</td>\n",
              "      <td>0.661780</td>\n",
              "      <td>0.831046</td>\n",
              "      <td>0.601164</td>\n",
              "      <td>0.834938</td>\n",
              "      <td>0.828581</td>\n",
              "      <td>0.834938</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 21:01:00,590] Trial 6 finished with value: 0.6011644832605532 and parameters: {'learning_rate': 8.753711913313763e-05, 'num_train_epochs': 7, 'warmup_steps': 239, 'weight_decay': 0.04841925743157053, 'per_device_train_batch_size': 32}. Best is trial 1 with value: 0.6022401184856059.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='175' max='175' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [175/175 02:46, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.516700</td>\n",
              "      <td>1.023567</td>\n",
              "      <td>0.628894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.739603</td>\n",
              "      <td>0.547013</td>\n",
              "      <td>0.739603</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.862900</td>\n",
              "      <td>0.734833</td>\n",
              "      <td>0.710736</td>\n",
              "      <td>0.269048</td>\n",
              "      <td>0.770322</td>\n",
              "      <td>0.682066</td>\n",
              "      <td>0.770322</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.707300</td>\n",
              "      <td>0.616027</td>\n",
              "      <td>0.775900</td>\n",
              "      <td>0.463388</td>\n",
              "      <td>0.802561</td>\n",
              "      <td>0.768989</td>\n",
              "      <td>0.802561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.562800</td>\n",
              "      <td>0.581800</td>\n",
              "      <td>0.793982</td>\n",
              "      <td>0.500256</td>\n",
              "      <td>0.811127</td>\n",
              "      <td>0.790214</td>\n",
              "      <td>0.811127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.455400</td>\n",
              "      <td>0.592005</td>\n",
              "      <td>0.799033</td>\n",
              "      <td>0.506376</td>\n",
              "      <td>0.811035</td>\n",
              "      <td>0.803173</td>\n",
              "      <td>0.811035</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.349600</td>\n",
              "      <td>0.631377</td>\n",
              "      <td>0.804584</td>\n",
              "      <td>0.533373</td>\n",
              "      <td>0.821397</td>\n",
              "      <td>0.801114</td>\n",
              "      <td>0.821397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.284200</td>\n",
              "      <td>0.615243</td>\n",
              "      <td>0.816411</td>\n",
              "      <td>0.564516</td>\n",
              "      <td>0.823147</td>\n",
              "      <td>0.812336</td>\n",
              "      <td>0.823147</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 21:03:48,270] Trial 7 finished with value: 0.564516129032258 and parameters: {'learning_rate': 0.0002716642086974459, 'num_train_epochs': 7, 'warmup_steps': 245, 'weight_decay': 0.045952914701750794, 'per_device_train_batch_size': 128}. Best is trial 1 with value: 0.6022401184856059.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='579' max='965' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [579/965 01:30 < 01:00, 6.36 it/s, Epoch 3/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.651200</td>\n",
              "      <td>0.593382</td>\n",
              "      <td>0.785445</td>\n",
              "      <td>0.499370</td>\n",
              "      <td>0.808686</td>\n",
              "      <td>0.791538</td>\n",
              "      <td>0.808686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.502800</td>\n",
              "      <td>0.519901</td>\n",
              "      <td>0.809489</td>\n",
              "      <td>0.557277</td>\n",
              "      <td>0.825404</td>\n",
              "      <td>0.805772</td>\n",
              "      <td>0.825404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.389700</td>\n",
              "      <td>0.575210</td>\n",
              "      <td>0.817785</td>\n",
              "      <td>0.568953</td>\n",
              "      <td>0.825542</td>\n",
              "      <td>0.814950</td>\n",
              "      <td>0.825542</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 21:05:20,036] Trial 8 pruned. \n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='245' max='245' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [245/245 02:01, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.997400</td>\n",
              "      <td>0.724241</td>\n",
              "      <td>0.720186</td>\n",
              "      <td>0.307927</td>\n",
              "      <td>0.772763</td>\n",
              "      <td>0.688492</td>\n",
              "      <td>0.772763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.689400</td>\n",
              "      <td>0.598928</td>\n",
              "      <td>0.775326</td>\n",
              "      <td>0.435806</td>\n",
              "      <td>0.799337</td>\n",
              "      <td>0.783288</td>\n",
              "      <td>0.799337</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.563700</td>\n",
              "      <td>0.552931</td>\n",
              "      <td>0.810994</td>\n",
              "      <td>0.550939</td>\n",
              "      <td>0.822134</td>\n",
              "      <td>0.808657</td>\n",
              "      <td>0.822134</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.581851</td>\n",
              "      <td>0.810506</td>\n",
              "      <td>0.535232</td>\n",
              "      <td>0.815733</td>\n",
              "      <td>0.812398</td>\n",
              "      <td>0.815733</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.271000</td>\n",
              "      <td>0.582042</td>\n",
              "      <td>0.829732</td>\n",
              "      <td>0.598138</td>\n",
              "      <td>0.835582</td>\n",
              "      <td>0.826679</td>\n",
              "      <td>0.835582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 21:07:23,241] Trial 9 finished with value: 0.5981377339356504 and parameters: {'learning_rate': 0.00025510156716585506, 'num_train_epochs': 5, 'warmup_steps': 210, 'weight_decay': 0.013547486947309825, 'per_device_train_batch_size': 64}. Best is trial 1 with value: 0.6022401184856059.\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='193' max='1544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 193/1544 00:28 < 03:23, 6.65 it/s, Epoch 1/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.770700</td>\n",
              "      <td>0.691822</td>\n",
              "      <td>0.746028</td>\n",
              "      <td>0.384952</td>\n",
              "      <td>0.782527</td>\n",
              "      <td>0.725634</td>\n",
              "      <td>0.782527</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 21:07:52,916] Trial 10 pruned. \n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='386' max='2702' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 386/2702 00:38 < 03:49, 10.07 it/s, Epoch 1/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.657100</td>\n",
              "      <td>0.593171</td>\n",
              "      <td>0.782755</td>\n",
              "      <td>0.481167</td>\n",
              "      <td>0.805140</td>\n",
              "      <td>0.780801</td>\n",
              "      <td>0.805140</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 21:08:31,999] Trial 11 pruned. \n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='386' max='3088' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 386/3088 00:38 < 04:28, 10.07 it/s, Epoch 1/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>0.585408</td>\n",
              "      <td>0.793325</td>\n",
              "      <td>0.501457</td>\n",
              "      <td>0.810160</td>\n",
              "      <td>0.789493</td>\n",
              "      <td>0.810160</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 21:09:10,944] Trial 12 pruned. \n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='193' max='772' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [193/772 00:28 < 01:27, 6.64 it/s, Epoch 1/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.749700</td>\n",
              "      <td>0.681428</td>\n",
              "      <td>0.753588</td>\n",
              "      <td>0.404876</td>\n",
              "      <td>0.786303</td>\n",
              "      <td>0.735890</td>\n",
              "      <td>0.786303</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "[I 2024-04-28 21:09:40,574] Trial 13 pruned. \n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='386' max='2316' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 386/2316 00:38 < 03:11, 10.09 it/s, Epoch 1/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.681700</td>\n",
              "      <td>0.599386</td>\n",
              "      <td>0.784802</td>\n",
              "      <td>0.481576</td>\n",
              "      <td>0.804034</td>\n",
              "      <td>0.783118</td>\n",
              "      <td>0.804034</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2024-04-28 21:10:19,442] Trial 14 pruned. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trials"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLYVAJvgEpyc",
        "outputId": "e38abbc0-11a0-4cf5-8ee1-46b2de0ad65b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='1', objective=0.6022401184856059, hyperparameters={'learning_rate': 0.00021437583926908025, 'num_train_epochs': 7, 'warmup_steps': 261, 'weight_decay': 0.03953905927366381, 'per_device_train_batch_size': 16}, run_summary=None)"
            ]
          },
          "metadata": {},
          "execution_count": 514
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training with Optimal Hyperparameters"
      ],
      "metadata": {
        "id": "WdWzbQ5LSxAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "IVVWvWvKjQja",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "f41d5844-0818-482f-91b3-79fa892a0141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1351' max='1351' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1351/1351 02:24, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>0accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.660200</td>\n",
              "      <td>0.615096</td>\n",
              "      <td>0.783436</td>\n",
              "      <td>0.464000</td>\n",
              "      <td>0.802100</td>\n",
              "      <td>0.788328</td>\n",
              "      <td>0.802100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.571600</td>\n",
              "      <td>0.555714</td>\n",
              "      <td>0.790384</td>\n",
              "      <td>0.503467</td>\n",
              "      <td>0.818404</td>\n",
              "      <td>0.794455</td>\n",
              "      <td>0.818404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.437800</td>\n",
              "      <td>0.570828</td>\n",
              "      <td>0.815805</td>\n",
              "      <td>0.556363</td>\n",
              "      <td>0.823884</td>\n",
              "      <td>0.812235</td>\n",
              "      <td>0.823884</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.273600</td>\n",
              "      <td>0.593348</td>\n",
              "      <td>0.824684</td>\n",
              "      <td>0.583392</td>\n",
              "      <td>0.827569</td>\n",
              "      <td>0.825344</td>\n",
              "      <td>0.827569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.171300</td>\n",
              "      <td>0.670793</td>\n",
              "      <td>0.828125</td>\n",
              "      <td>0.590971</td>\n",
              "      <td>0.832266</td>\n",
              "      <td>0.826483</td>\n",
              "      <td>0.832266</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.112100</td>\n",
              "      <td>0.728773</td>\n",
              "      <td>0.825602</td>\n",
              "      <td>0.582805</td>\n",
              "      <td>0.831668</td>\n",
              "      <td>0.821517</td>\n",
              "      <td>0.831668</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.078600</td>\n",
              "      <td>0.790125</td>\n",
              "      <td>0.828112</td>\n",
              "      <td>0.589491</td>\n",
              "      <td>0.833694</td>\n",
              "      <td>0.824460</td>\n",
              "      <td>0.833694</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1351, training_loss=0.3809327110124243, metrics={'train_runtime': 146.5142, 'train_samples_per_second': 147.487, 'train_steps_per_second': 9.221, 'total_flos': 992587316340060.0, 'train_loss': 0.3809327110124243, 'epoch': 7.0})"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = trainer.evaluate()\n",
        "for item, value in eval_result.items():\n",
        "    print(f\"{item}: {value}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "o3iUk7UOFzRi",
        "outputId": "e9b05073-8173-4aba-ca65-35c0bb0d378b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='13' max='13' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [13/13 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eval_loss: 0.09071370214223862\n",
            "eval_f1: 0.4383088869715272\n",
            "eval_roc_auc: 0.8250157931661872\n",
            "eval_hamming loss: 0.059964076820338046\n",
            "eval_runtime: 1.0777\n",
            "eval_samples_per_second: 384.164\n",
            "eval_steps_per_second: 12.063\n",
            "epoch: 12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing"
      ],
      "metadata": {
        "id": "GRAtLcULHwzM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# Defining evaluation metrics\n",
        "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
        "def test_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    y_pred = [\n",
        "        p for prediction, label in zip(predictions, labels)\n",
        "        for p, l in zip(prediction, label) if l != -100\n",
        "    ]\n",
        "    y_true = [\n",
        "        l for label in labels\n",
        "        for l in label if l != -100\n",
        "    ]\n",
        "    labs = [1,2,3,4,5,6,7,8]\n",
        "    overall_f1_macro = f1_score(y_true=y_true, y_pred=y_pred, average='macro', labels=labs).tolist()\n",
        "    overall_f1_micro = f1_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs).tolist()\n",
        "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "    precision_overall = precision_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs)\n",
        "    recall_overall = recall_score(y_true=y_true, y_pred=y_pred, average='micro', labels=labs)\n",
        "\n",
        "    #accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "    recall = recall_score(y_true=y_true, y_pred=y_pred, average=None, labels=labs).tolist()\n",
        "\n",
        "    results = {'F1': f1_micro_average,\n",
        "               'Overal F1 Macro': overall_f1_macro,\n",
        "               'Overall Accuracy': overall_f1_micro,\n",
        "               #'accuracy': accuracy,\n",
        "               'Precision': precision,\n",
        "               'Recall': recall,\n",
        "               'Precision Overall': precision_overall,\n",
        "               'Recall Overall': recall_overall}\n",
        "\n",
        "    return results"
      ],
      "metadata": {
        "id": "IJAe_yfPPzrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_result = trainer.predict(test['inputs'].values)\n",
        "\n",
        "# Print default metrics collected during prediction\n",
        "for item, value in test_result.metrics.items():\n",
        "    print(f\"{item}: {value}\")\n",
        "\n",
        "predictions = torch.Tensor(test_result.predictions)\n",
        "labels = torch.Tensor(test_result.label_ids)\n",
        "\n",
        "# Compute class-wise metrics\n",
        "#thresholds = [0.15, 0.5, 0.5, 0.5, 0.5, 0.19, 0.5, 0.5]\n",
        "results = test_metrics((predictions, labels))\n",
        "df = pd.DataFrame.from_dict(results)\n",
        "#df.drop(columns = ['f1', 'roc_auc', 'hamming_loss'], inplace=True)\n",
        "df.index = [['1. Add/Del - Function Word', '2. Add/Del - Content Word', '3. Change of Order',\n",
        "             '4. Substitution - Synonym', '5. Substitution - Contextual Synonym', '6. Substitution - Morphological',\n",
        "             '7. Substitution - Spelling and Format', '8. Add/Del - Punctuation']]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "350c5841-70b0-428d-f0bc-e202e85798ca",
        "id": "6ZvS6i0n53Sb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test_loss: 0.708419919013977\n",
            "test_f1: 0.8190371055664056\n",
            "test_accuracy: 0.6173206327012148\n",
            "test_0accuracy: 0.8250701590271281\n",
            "test_precision: 0.8166889519987208\n",
            "test_recall: 0.8250701590271281\n",
            "test_runtime: 0.8199\n",
            "test_samples_per_second: 486.632\n",
            "test_steps_per_second: 30.491\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             F1  Overal F1 Macro  \\\n",
              "1. Add/Del - Function Word             0.397516         0.570549   \n",
              "2. Add/Del - Content Word              0.737399         0.570549   \n",
              "3. Change of Order                     0.561488         0.570549   \n",
              "4. Substitution - Synonym              0.625709         0.570549   \n",
              "5. Substitution - Contextual Synonym   0.508521         0.570549   \n",
              "6. Substitution - Morphological        0.557576         0.570549   \n",
              "7. Substitution - Spelling and Format  0.564530         0.570549   \n",
              "8. Add/Del - Punctuation               0.611650         0.570549   \n",
              "\n",
              "                                       Overall Accuracy  Precision    Recall  \\\n",
              "1. Add/Del - Function Word                     0.617321   0.500000  0.329897   \n",
              "2. Add/Del - Content Word                      0.617321   0.753129  0.722313   \n",
              "3. Change of Order                             0.617321   0.663830  0.486486   \n",
              "4. Substitution - Synonym                      0.617321   0.614670  0.637151   \n",
              "5. Substitution - Contextual Synonym           0.617321   0.577406  0.454321   \n",
              "6. Substitution - Morphological                0.617321   0.666667  0.479167   \n",
              "7. Substitution - Spelling and Format          0.617321   0.570707  0.558484   \n",
              "8. Add/Del - Punctuation                       0.617321   0.750000  0.516393   \n",
              "\n",
              "                                       Precision Overall  Recall Overall  \n",
              "1. Add/Del - Function Word                      0.656994        0.582166  \n",
              "2. Add/Del - Content Word                       0.656994        0.582166  \n",
              "3. Change of Order                              0.656994        0.582166  \n",
              "4. Substitution - Synonym                       0.656994        0.582166  \n",
              "5. Substitution - Contextual Synonym            0.656994        0.582166  \n",
              "6. Substitution - Morphological                 0.656994        0.582166  \n",
              "7. Substitution - Spelling and Format           0.656994        0.582166  \n",
              "8. Add/Del - Punctuation                        0.656994        0.582166  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1c71a041-e9e2-44a3-ba22-e28b1072213f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>F1</th>\n",
              "      <th>Overal F1 Macro</th>\n",
              "      <th>Overall Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Precision Overall</th>\n",
              "      <th>Recall Overall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1. Add/Del - Function Word</th>\n",
              "      <td>0.397516</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.329897</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2. Add/Del - Content Word</th>\n",
              "      <td>0.737399</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.753129</td>\n",
              "      <td>0.722313</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3. Change of Order</th>\n",
              "      <td>0.561488</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.663830</td>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4. Substitution - Synonym</th>\n",
              "      <td>0.625709</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.614670</td>\n",
              "      <td>0.637151</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5. Substitution - Contextual Synonym</th>\n",
              "      <td>0.508521</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.577406</td>\n",
              "      <td>0.454321</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6. Substitution - Morphological</th>\n",
              "      <td>0.557576</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.479167</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7. Substitution - Spelling and Format</th>\n",
              "      <td>0.564530</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.570707</td>\n",
              "      <td>0.558484</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8. Add/Del - Punctuation</th>\n",
              "      <td>0.611650</td>\n",
              "      <td>0.570549</td>\n",
              "      <td>0.617321</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>0.516393</td>\n",
              "      <td>0.656994</td>\n",
              "      <td>0.582166</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1c71a041-e9e2-44a3-ba22-e28b1072213f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1c71a041-e9e2-44a3-ba22-e28b1072213f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1c71a041-e9e2-44a3-ba22-e28b1072213f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6d6fb221-6cba-4f82-ba1e-9f003870ef60\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6d6fb221-6cba-4f82-ba1e-9f003870ef60')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6d6fb221-6cba-4f82-ba1e-9f003870ef60 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_454f452e-b1bd-43ae-a58a-a4ea481e64c8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_454f452e-b1bd-43ae-a58a-a4ea481e64c8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"F1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09757453878104867,\n        \"min\": 0.3975155279503106,\n        \"max\": 0.7373990531885268,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7373990531885268,\n          0.5575757575757576,\n          0.3975155279503106\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overal F1 Macro\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5705485485876536,\n        \"max\": 0.5705485485876536,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5705485485876536\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Overall Accuracy\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.6173206327012148,\n        \"max\": 0.6173206327012148,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6173206327012148\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0886957844428602,\n        \"min\": 0.5,\n        \"max\": 0.7531285551763367,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7531285551763367\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11911530729344837,\n        \"min\": 0.32989690721649484,\n        \"max\": 0.7223131478450627,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.7223131478450627\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision Overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.6569940476190477,\n        \"max\": 0.6569940476190477,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6569940476190477\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall Overall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 0.5821658150651063,\n        \"max\": 0.5821658150651063,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.5821658150651063\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    }
  ]
}